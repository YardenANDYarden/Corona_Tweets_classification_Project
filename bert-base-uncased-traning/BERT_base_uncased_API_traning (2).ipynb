{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8fwlj7vYQBb",
        "outputId": "d0ad84a3-b205-42bd-e1f9-828e0b523748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 1) Connect to Google Drive\n",
        "# ========================================\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "#MODEL_DIR = \"/content/drive/MyDrive/deep_learning\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "18LqQBe_YmqH",
        "outputId": "dcc2c8e6-a525-4446-dfb5-84c2bb57fd7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.21.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.34.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.14.1)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 2) Install required libraries\n",
        "# ========================================\n",
        "!pip install -U transformers datasets accelerate evaluate optuna wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRlucwrcZzDm",
        "outputId": "4d687675-29b7-4774-bafc-568a31c9553a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_lUu73RwbbY",
        "outputId": "0f643e68-9bb0-40ff-c318-4989b13b5a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWSgKFUoYqzs"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 3) Import libraries\n",
        "# ========================================\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "import evaluate\n",
        "import wandb\n",
        "import types\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQr3wGwNYsO7",
        "outputId": "2bb54fa4-e33d-44d1-80dc-eef383f6d730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available and select device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "KsWmAknYYsvz",
        "outputId": "bbf364f6-7b1a-4a36-9463-54ebe27c51f9"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myardenshalom\u001b[0m (\u001b[33myardenshalom-tel-aviv-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ========================================\n",
        "# 4) Setup Weights & Biases logging\n",
        "# ========================================\n",
        "os.environ[\"WANDB_PROJECT\"] = \"covid-HF-YS1\"\n",
        "os.environ[\"WANDB_WATCH\"] = \"all\"\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBF3Ga4FY28M"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ========================================\n",
        "# 3) Load data (your preprocessed CSVs)\n",
        "# ========================================\n",
        "#train_df = pd.read_csv('/content/drive/MyDrive/deep_learning/train_processed.csv', encoding='latin1')\n",
        "#eval_df  = pd.read_csv('/content/drive/MyDrive/deep_learning/val_processed.csv',   encoding='latin1')\n",
        "#test_df  = pd.read_csv('/content/drive/MyDrive/deep_learning/test_processed.csv',  encoding='latin1')\n",
        "\n",
        "\n",
        "MODEL_DIR =Path.cwd()  # models/bert-base-uncased/\n",
        "# Navigate from model folder to data folder\n",
        "current_dir = Path.cwd()  # models/bert-base-uncased/\n",
        "models_dir = current_dir.parent  # models/\n",
        "project_root = models_dir.parent  # project root\n",
        "data_dir = models_dir / 'data'\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(data_dir / 'train_processed.csv', encoding='latin1')\n",
        "eval_df = pd.read_csv(data_dir / 'val_processed.csv', encoding='latin1')\n",
        "test_df = pd.read_csv(data_dir / 'test_processed.csv', encoding='latin1')\n",
        "\n",
        "print(f\"Data loaded from: {data_dir}\")\n",
        "print(f\"Train shape: {train_df.shape}\")\n",
        "print(f\"Val shape: {eval_df.shape}\")\n",
        "print(f\"Test shape: {test_df.shape}\")\n",
        "\n",
        "# Create label mappings\n",
        "ordered_labels = ['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive']\n",
        "label2id = {label: i for i, label in enumerate(ordered_labels)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "\n",
        "train_df[\"label\"] = train_df[\"Sentiment\"].map(label2id)\n",
        "eval_df[\"label\"] = eval_df[\"Sentiment\"].map(label2id)\n",
        "test_df[\"label\"] = test_df[\"Sentiment\"].map(label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "e0b96efa8f54416da55b0422eae67615",
            "28150c8c3ef34365b6adf1415b8f79ca",
            "bb00e98ee4db4b88b14ebcd7f2341196",
            "7885e6cf852c4ef1b06700d3c24a330c",
            "a13e5cf894b04658a2194817e589b8e9",
            "803192f0d8ef4614a8a06484581ce909",
            "1fba0344ea2d42f0bb5a6e4bc23ddb37",
            "ac3b2905e32d4eddac6f91ed42d63ae5",
            "01b7fd33a6bc498bb9eb8f729ed098e2",
            "712fdfcbfbe74a8e8ecbc77d865fc14f",
            "515a21b75e40472eaad681eef51a103d",
            "79550c51f8a44fdcabb8b80b5e2eadb6",
            "5da9e33181a54abcabfebabc171a0574",
            "2c5a5ca6f07743469342bc9a836232ff",
            "b19b1c8f204742119cc18fb1f3bae855",
            "46dd89328fee4a87b1c81dd36e1e1ec5",
            "7e5903bb8c2a4c4bb84ce6bd7f2685ce",
            "36785dee092f4722bb5e2878a661296b",
            "07cc04f190384e2fa50c6534081cbd79",
            "eac1c486c0724ccfa4b393581f189f82",
            "d60813bfef2f4b058837cdcc0889526f",
            "a48638c27e874e028eadfaac7f960dd9",
            "2b02542bc0b548fba3c51ccea4e46f05",
            "63c857e4044748e998fafcbdb7179b6b",
            "c93faa21bfcc4a6fae9c64eeed5101b4",
            "920856563d5a441598fb7b9a538da4a5",
            "be02dce09c054d39827fc1681431a990",
            "5a173d560e78405288fe55d6654354b3",
            "bf7a14c5b4c44880b45c5b70a03d1898",
            "b4c5435005bc46f2bca3763ca14fee9d",
            "d27accfe0d2143f2bd7dae848d05328d",
            "8f90aee836994a2d87dbb3269b8eb49d",
            "881ec87c6a5c47cb879e52aa7e03c341"
          ]
        },
        "id": "TQjHPD4tebL6",
        "outputId": "c81808f0-20e4-46b3-c8d9-2eaafdb80035"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32925 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0b96efa8f54416da55b0422eae67615"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8232 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79550c51f8a44fdcabb8b80b5e2eadb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3798 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b02542bc0b548fba3c51ccea4e46f05"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ========================================\n",
        "# 4) Build HF Datasets and tokenize\n",
        "# ========================================\n",
        "\n",
        "model_ckpt = \"bert-base-uncased\"                 # <-- BERT cased\n",
        "tokenizer  = AutoTokenizer.from_pretrained(model_ckpt, use_fast=True)\n",
        "\n",
        "specials = {\"additional_special_tokens\": [\"<httpurl>\", \"<user>\", \"<hashtag>\", \"<emoji>\"]}\n",
        "tokenizer.add_special_tokens(specials)\n",
        "\n",
        "def tok(batch):\n",
        "    return tokenizer(\n",
        "        batch[\"ProcessedTweet\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "ds = DatasetDict({\n",
        "    \"train\": Dataset.from_pandas(train_df[[\"ProcessedTweet\",\"label\"]].rename(columns={\"label\":\"labels\"})),\n",
        "    \"validation\": Dataset.from_pandas(eval_df[[\"ProcessedTweet\",\"label\"]].rename(columns={\"label\":\"labels\"})),\n",
        "    \"test\": Dataset.from_pandas(test_df[[\"ProcessedTweet\",\"label\"]].rename(columns={\"label\":\"labels\"})),\n",
        "})\n",
        "\n",
        "ds_tok = ds.map(tok, batched=True)\n",
        "ds_tok = ds_tok.remove_columns([\"ProcessedTweet\"])\n",
        "ds_tok.set_format(\"torch\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KCSibDnkuk5"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 5) Optional: class weights (to handle class imbalance)\n",
        "# ========================================\n",
        "def compute_class_weights(int_labels, num_labels):\n",
        "    \"\"\"\n",
        "    Compute inverse-frequency class weights normalized around 1.0\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "    counts = np.bincount(int_labels, minlength=num_labels)\n",
        "    weights = (counts.sum() / (counts + 1e-9)) / num_labels\n",
        "    return weights / weights.mean()\n",
        "\n",
        "class_weights = compute_class_weights(\n",
        "    train_df[\"label\"].to_numpy(),\n",
        "    num_labels=len(ordered_labels)\n",
        ")\n",
        "class_weights\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmM2P2qekvAh"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 6) Custom BERT with configurable dropout (CLS pooling)\n",
        "# ========================================\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "class BertWithDropout(nn.Module):\n",
        "    \"\"\"\n",
        "    Custom BERT classification head:\n",
        "      - Takes the [CLS] token embedding (token at position 0)\n",
        "      - Applies configurable dropout\n",
        "      - Passes through a linear layer to produce logits for num_labels\n",
        "      Works with 'bert-base-uncased' or any BERT-based model via AutoModel.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name: str, num_labels: int, dropout_rate: float = 0.2):\n",
        "        super().__init__()\n",
        "        self.backbone = AutoModel.from_pretrained(model_name)\n",
        "        self.dropout  = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(self.backbone.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls = outputs.last_hidden_state[:, 0, :]\n",
        "        x = self.dropout(cls)\n",
        "        logits = self.classifier(x)\n",
        "        return {\"logits\": logits}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-_rh2p7kxfd"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 7) Weighted loss wrapper for Trainer\n",
        "# ========================================\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "ce_loss = nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float))\n",
        "\n",
        "def custom_compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "    labels  = inputs.get(\"labels\")\n",
        "    outputs = model(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs.get(\"attention_mask\")\n",
        "    )\n",
        "    logits = outputs[\"logits\"] if isinstance(outputs, dict) else outputs.logits\n",
        "    ce = nn.CrossEntropyLoss(weight=class_weights_tensor.to(logits.device))\n",
        "\n",
        "    loss = ce(logits, labels)\n",
        "    return (loss, outputs) if return_outputs else loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oASEghZZk1YU"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 8) Metrics (accuracy + F1 micro/macro/weighted)\n",
        "# ========================================\n",
        "import evaluate\n",
        "acc = evaluate.load(\"accuracy\")\n",
        "f1  = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics_fn(eval_pred):\n",
        "    \"\"\"\n",
        "    HF Trainer metrics: returns dict with accuracy and F1 variants\n",
        "    \"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\":      acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1_micro\":      f1.compute(predictions=preds, references=labels, average=\"micro\")[\"f1\"],\n",
        "        \"f1_macro\":      f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
        "        \"f1_weighted\":   f1.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"],\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-tEk8Rtk4A_"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 9) Trainer factory (no HF checkpoints) + BestWeightsSaver callback\n",
        "#    - Saves ONLY best weights (state_dict) per run to a temp .pt\n",
        "#    - EarlyStopping relies on eval_f1_weighted from compute_metrics_fn\n",
        "# ========================================\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import types\n",
        "from datetime import datetime\n",
        "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback, TrainerCallback\n",
        "\n",
        "class BestWeightsSaver(TrainerCallback):\n",
        "    \"\"\"\n",
        "    Whenever 'eval_f1_weighted' improves, save ONLY model.state_dict() to `best_weights_path`.\n",
        "    \"\"\"\n",
        "    def __init__(self, best_weights_path: str, metric_name: str = \"eval_f1_weighted\"):\n",
        "        self.best_weights_path = best_weights_path\n",
        "        self.metric_name = metric_name\n",
        "        self.best_score = None\n",
        "        self._trainer = None  # injected on attach\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "        if not metrics or self.metric_name not in metrics:\n",
        "            return\n",
        "        score = float(metrics[self.metric_name])\n",
        "        if (self.best_score is None) or (score > self.best_score):\n",
        "            self.best_score = score\n",
        "            torch.save(self._trainer.model.state_dict(), self.best_weights_path)\n",
        "\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "\n",
        "\n",
        "def make_trainer(\n",
        "    output_dir,\n",
        "    dropout_rate=0.2,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.06,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=1,\n",
        "    label_smoothing_factor=0.0,\n",
        "    fp16=True,\n",
        "    report_to_wandb=False,\n",
        "    run_name=\"trial\",\n",
        "    best_weights_path=\"/tmp/best_weights.pt\",\n",
        "):\n",
        "    # Build model with your custom head\n",
        "    model = BertWithDropout(\n",
        "        model_name=MODEL_NAME,\n",
        "        num_labels=len(ordered_labels),\n",
        "        dropout_rate=dropout_rate\n",
        "    )\n",
        "\n",
        "    # Absolutely NO HF checkpoints to Drive\n",
        "    args = TrainingArguments(\n",
        "        output_dir=output_dir,                 # keep this under /tmp to avoid Drive writes\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",                    # no checkpoints\n",
        "        load_best_model_at_end=False,          # we handle \"best\" ourselves\n",
        "        metric_for_best_model=\"f1_weighted\",   # required for EarlyStopping\n",
        "        greater_is_better=True,\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=50,\n",
        "        per_device_train_batch_size=per_device_train_batch_size,\n",
        "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        warmup_ratio=warmup_ratio,\n",
        "        learning_rate=learning_rate,\n",
        "        weight_decay=weight_decay,\n",
        "        lr_scheduler_type=lr_scheduler_type,\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        label_smoothing_factor=label_smoothing_factor,\n",
        "        max_grad_norm=1.0,\n",
        "        fp16=fp16,\n",
        "        report_to=([\"wandb\"] if report_to_wandb else [\"none\"]),\n",
        "        run_name=run_name,\n",
        "        seed=42,\n",
        "        dataloader_num_workers=2,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=ds_tok[\"train\"],\n",
        "        eval_dataset=ds_tok[\"validation\"],\n",
        "        processing_class=tokenizer,           # future-proof vs tokenizer=\n",
        "        compute_metrics=compute_metrics_fn,\n",
        "    )\n",
        "\n",
        "    # Custom weighted CE loss (device-aware)\n",
        "    trainer.compute_loss = types.MethodType(custom_compute_loss, trainer)\n",
        "\n",
        "    # Early stopping (small patience to keep it agile)\n",
        "    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
        "\n",
        "    # Attach best-weights saver\n",
        "    best_cb = BestWeightsSaver(best_weights_path=best_weights_path, metric_name=\"eval_f1_weighted\")\n",
        "    best_cb._trainer = trainer\n",
        "    trainer.add_callback(best_cb)\n",
        "\n",
        "    return trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn0DevqOo90F"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 10) Generic experiment runner (replaces your old \"part 10\")\n",
        "#     - tune_once(): Optuna tuning for a given search space\n",
        "#     - final_train_and_save(): long-ish final run + save ONLY weights to Drive\n",
        "# ========================================\n",
        "import json\n",
        "import optuna\n",
        "import pandas as pd\n",
        "\n",
        "MODEL_DIR  =data_dir\n",
        "EXPERIMENTS_LOG = os.path.join(MODEL_DIR, \"HF_experiments_log_3.csv\")  # append-only CSV\n",
        "\n",
        "def now_tag():\n",
        "    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "def temp_paths(tag: str):\n",
        "    stamp = now_tag()\n",
        "    out_dir = f\"/tmp/{tag}_{stamp}\"\n",
        "    best_pt = f\"/tmp/{tag}_{stamp}_best.pt\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    return out_dir, best_pt\n",
        "\n",
        "def append_row_to_log(row: dict):\n",
        "    if os.path.exists(EXPERIMENTS_LOG):\n",
        "        df = pd.read_csv(EXPERIMENTS_LOG)\n",
        "        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "    else:\n",
        "        df = pd.DataFrame([row])\n",
        "    df.to_csv(EXPERIMENTS_LOG, index=False)\n",
        "\n",
        "def tune_once(config_name: str, search_space_fn, n_trials=10, tune_epochs=(3,6)):\n",
        "    \"\"\"\n",
        "    Run Optuna on a provided search space function.\n",
        "    Returns (best_params, best_value).\n",
        "    \"\"\"\n",
        "    def objective(trial: optuna.trial.Trial):\n",
        "        hp = search_space_fn(trial, tune_epochs)\n",
        "        out_dir, best_pt = temp_paths(f\"tune_{config_name}_t{trial.number}\")\n",
        "        trainer = make_trainer(\n",
        "            output_dir=out_dir,\n",
        "            dropout_rate=hp[\"dropout_rate\"],\n",
        "            learning_rate=hp[\"learning_rate\"],\n",
        "            weight_decay=hp[\"weight_decay\"],\n",
        "            warmup_ratio=hp[\"warmup_ratio\"],\n",
        "            lr_scheduler_type=hp[\"lr_scheduler_type\"],\n",
        "            per_device_train_batch_size=hp[\"per_device_train_batch_size\"],\n",
        "            per_device_eval_batch_size=64,\n",
        "            num_train_epochs=hp[\"num_train_epochs\"],\n",
        "            gradient_accumulation_steps=hp[\"gradient_accumulation_steps\"],\n",
        "            label_smoothing_factor=hp[\"label_smoothing_factor\"],\n",
        "            fp16=True,\n",
        "            report_to_wandb=False,\n",
        "            run_name=f\"{config_name}-trial-{trial.number}\",\n",
        "            best_weights_path=best_pt\n",
        "        )\n",
        "        trainer.train()\n",
        "        metrics = trainer.evaluate(ds_tok[\"validation\"])\n",
        "        score = float(metrics.get(\"eval_f1_weighted\") or metrics.get(\"f1_weighted\") or 0.0)\n",
        "\n",
        "        # Clean temp\n",
        "        try:\n",
        "            if os.path.exists(best_pt):\n",
        "                os.remove(best_pt)\n",
        "        except OSError:\n",
        "            pass\n",
        "        del trainer\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "        return score\n",
        "\n",
        "    study_name = f\"{config_name}_{now_tag()}\"\n",
        "    study = optuna.create_study(direction=\"maximize\", study_name=study_name)\n",
        "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "    # log summary\n",
        "    row = {\n",
        "        \"time\": now_tag(),\n",
        "        \"phase\": \"tuning\",\n",
        "        \"config\": config_name,\n",
        "        \"study_name\": study_name,\n",
        "        \"best_value_f1w\": study.best_value,\n",
        "        \"best_params_json\": json.dumps(study.best_trial.params, ensure_ascii=False),\n",
        "        \"n_trials\": n_trials,\n",
        "        \"tune_epochs\": str(tune_epochs),\n",
        "    }\n",
        "    append_row_to_log(row)\n",
        "    print(f\"======= Tuning finished: {config_name} | best f1_weighted={study.best_value:.4f}\")\n",
        "    return study.best_trial.params, study.best_value\n",
        "\n",
        "def final_train_and_save(config_name: str, best_params: dict, final_epochs=12, save_name=None):\n",
        "    \"\"\"\n",
        "    Final training with best params (longer, ES active), save ONLY weights .pt to Drive,\n",
        "    log val/test to CSV.\n",
        "    \"\"\"\n",
        "    out_dir, best_pt = temp_paths(f\"final_{config_name}\")\n",
        "    trainer = make_trainer(\n",
        "        output_dir=out_dir,\n",
        "        dropout_rate=best_params.get(\"dropout_rate\", 0.2),\n",
        "        learning_rate=best_params.get(\"learning_rate\", 2e-5),\n",
        "        weight_decay=best_params.get(\"weight_decay\", 0.01),\n",
        "        warmup_ratio=best_params.get(\"warmup_ratio\", 0.06),\n",
        "        lr_scheduler_type=best_params.get(\"lr_scheduler_type\", \"linear\"),\n",
        "        per_device_train_batch_size=best_params.get(\"per_device_train_batch_size\", 32),\n",
        "        per_device_eval_batch_size=64,\n",
        "        num_train_epochs=final_epochs,\n",
        "        gradient_accumulation_steps=best_params.get(\"gradient_accumulation_steps\", 1),\n",
        "        label_smoothing_factor=best_params.get(\"label_smoothing_factor\", 0.0),\n",
        "        fp16=True,\n",
        "        report_to_wandb=False,\n",
        "        run_name=f\"{config_name}-final\",\n",
        "        best_weights_path=best_pt\n",
        "    )\n",
        "    trainer.train()\n",
        "    val_metrics  = trainer.evaluate(ds_tok[\"validation\"])\n",
        "    test_metrics = trainer.evaluate(ds_tok[\"test\"])\n",
        "\n",
        "    # Rebuild and save ONLY weights to Drive\n",
        "    model_for_save = BertWithDropout(\n",
        "        model_name=MODEL_NAME,\n",
        "        num_labels=len(ordered_labels),\n",
        "        dropout_rate=best_params.get(\"dropout_rate\", 0.2),\n",
        "    )\n",
        "    assert os.path.exists(best_pt), \"Temp best weights not found.\"\n",
        "    model_for_save.load_state_dict(torch.load(best_pt, map_location=\"cpu\"))\n",
        "\n",
        "    if save_name is None:\n",
        "        save_name = f\"HF_best_{config_name}_{now_tag()}.pt\"\n",
        "    drive_path = os.path.join(MODEL_DIR, save_name)\n",
        "    torch.save(model_for_save.state_dict(), drive_path)\n",
        "    print(f\"========= Final best weights saved to: {drive_path}\")\n",
        "\n",
        "    # cleanup temp\n",
        "    try:\n",
        "        os.remove(best_pt)\n",
        "    except OSError:\n",
        "        pass\n",
        "    del trainer, model_for_save\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    # append final results\n",
        "    row = {\n",
        "        \"time\": now_tag(),\n",
        "        \"phase\": \"final\",\n",
        "        \"config\": config_name,\n",
        "        \"val_f1_weighted\": float(val_metrics.get(\"eval_f1_weighted\", 0.0)),\n",
        "        \"val_accuracy\": float(val_metrics.get(\"eval_accuracy\", 0.0)),\n",
        "        \"test_f1_weighted\": float(test_metrics.get(\"eval_f1_weighted\", 0.0)),\n",
        "        \"test_accuracy\": float(test_metrics.get(\"eval_accuracy\", 0.0)),\n",
        "        \"saved_to\": drive_path,\n",
        "    }\n",
        "    append_row_to_log(row)\n",
        "    return drive_path, val_metrics, test_metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter selection summary:\n",
        "I used a broad, well-established search space that avoids task-specific assumptions and works reliably for BERT. The tuner explores learning rate on a log scale in the classic BERT range (\\~2e-5–5e-5), moderate weight decay (0.0–0.05) to preserve pretrained representations, dropout 0.10–0.30 for regularization, and a non-zero warmup ratio (\\~4–12%) to stabilize early updates. I allowed common schedulers (linear / cosine / cosine\\_with\\_restarts / polynomial), batch sizes 16/32 with optional gradient accumulation, and short tuning epochs (e.g., 4–6) with early stopping to keep the search fast. Model selection is by macro-F1 (robust under class imbalance), with class-weighted cross-entropy to counter skewed labels; I also log weighted-F1 and accuracy for completeness. For stability, I use gradient clipping and save only the best state\\_dict via a lightweight callback (no heavy HF checkpoints). In later refinement, I optionally apply discriminative learning rates (lower LR for lower encoder layers) and a slightly stronger warmup—generic, model-agnostic tweaks that often yield small but reliable gains without overfitting.\n"
      ],
      "metadata": {
        "id": "oCu0d0O1Li5h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmomx9FApTl3"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 11) Search spaces\n",
        "#     - Stage 1: broad (fresh run)\n",
        "# ========================================\n",
        "\n",
        "# Stage 1 (broad): good for a fresh, clean run\n",
        "def search_space_stage1(trial, tune_epochs):\n",
        "    return {\n",
        "        \"dropout_rate\": trial.suggest_float(\"dropout_rate\", 0.10, 0.30),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-6, 5e-5, log=True),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.00, 0.05),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.00, 0.12),\n",
        "        \"lr_scheduler_type\": trial.suggest_categorical(\"lr_scheduler_type\",\n",
        "                            [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\"]),\n",
        "        \"label_smoothing_factor\": trial.suggest_float(\"label_smoothing_factor\", 0.00, 0.08),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32]),\n",
        "        \"gradient_accumulation_steps\": trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2]),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", tune_epochs[0], tune_epochs[1]),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 891,
          "referenced_widgets": [
            "095b25d04604468e9c8598782e565265",
            "aeb654603686466caadbd0fd836f9188",
            "7e4bb7c45016421c99ee67ae9d7afac6",
            "9980398d43f7440daa1258cd28fc5e99",
            "06eac6d31845463caa2dd1d2e0cf04ff",
            "fd0d1229c117478498d20eaa7912253d",
            "aa45d1716fc446ffa3015a00b3ed7283",
            "5da63b03166e4686a5335785dd7bf6d8",
            "93d0fcf524e24255a74038298c8060e7",
            "90d46e9171b248c599c5827767518468",
            "77feed77f5514088a7283ef8d00d6dbd",
            "40d8878761f541d58a0131301ce072ff",
            "640aa3c6ed764d46b960b762e5dd567a",
            "110968ccca1a4631b83d51f0ac704f5b",
            "e1b90a08d0f64e52ad4c4fb66dd4fce3",
            "ab7fa6ed372d426a84366d4517f12841",
            "e0f00b51f51749b598e87019886b302f",
            "d6fe8f9709614a6cbc3b1ff51ba055a1",
            "d734f5190d8b49fcab100dc5304ce6aa",
            "901a99469a8242cebe6c413f71800900",
            "267fe7251fb449078a9127f6b876c29f",
            "1f23fb78613f45cb971296f08d6c7aa2"
          ]
        },
        "id": "fkBttmPWrUXz",
        "outputId": "5a7dbfcd-db8c-4da7-9ff0-7a3e9803718e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 14:31:38,262] A new study created in memory with name: stage1_broad_20250812_143138\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "095b25d04604468e9c8598782e565265",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40d8878761f541d58a0131301ce072ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6174' max='6174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6174/6174 05:14, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.793700</td>\n",
              "      <td>0.767247</td>\n",
              "      <td>0.653183</td>\n",
              "      <td>0.653183</td>\n",
              "      <td>0.663591</td>\n",
              "      <td>0.646858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.514400</td>\n",
              "      <td>0.489923</td>\n",
              "      <td>0.806122</td>\n",
              "      <td>0.806122</td>\n",
              "      <td>0.812403</td>\n",
              "      <td>0.805206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.378000</td>\n",
              "      <td>0.450924</td>\n",
              "      <td>0.818270</td>\n",
              "      <td>0.818270</td>\n",
              "      <td>0.823508</td>\n",
              "      <td>0.817602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.272200</td>\n",
              "      <td>0.454171</td>\n",
              "      <td>0.830904</td>\n",
              "      <td>0.830904</td>\n",
              "      <td>0.836396</td>\n",
              "      <td>0.830201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.218500</td>\n",
              "      <td>0.438455</td>\n",
              "      <td>0.849976</td>\n",
              "      <td>0.849976</td>\n",
              "      <td>0.854449</td>\n",
              "      <td>0.849757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.218100</td>\n",
              "      <td>0.444251</td>\n",
              "      <td>0.850340</td>\n",
              "      <td>0.850340</td>\n",
              "      <td>0.854858</td>\n",
              "      <td>0.850060</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 14:37:00,423] Trial 0 finished with value: 0.8500601029968764 and parameters: {'dropout_rate': 0.16280967184179887, 'learning_rate': 1.1042983963920488e-05, 'weight_decay': 0.034835462687443586, 'warmup_ratio': 0.11135169595986416, 'lr_scheduler_type': 'cosine', 'label_smoothing_factor': 0.056656027682059254, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 1, 'num_train_epochs': 6}. Best is trial 0 with value: 0.8500601029968764.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10290' max='10290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10290/10290 08:33, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.733700</td>\n",
              "      <td>0.754368</td>\n",
              "      <td>0.661808</td>\n",
              "      <td>0.661808</td>\n",
              "      <td>0.671737</td>\n",
              "      <td>0.654889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.584900</td>\n",
              "      <td>0.531049</td>\n",
              "      <td>0.781948</td>\n",
              "      <td>0.781948</td>\n",
              "      <td>0.787877</td>\n",
              "      <td>0.780676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.410800</td>\n",
              "      <td>0.483903</td>\n",
              "      <td>0.809767</td>\n",
              "      <td>0.809767</td>\n",
              "      <td>0.815953</td>\n",
              "      <td>0.808948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.342100</td>\n",
              "      <td>0.513058</td>\n",
              "      <td>0.809767</td>\n",
              "      <td>0.809767</td>\n",
              "      <td>0.815925</td>\n",
              "      <td>0.808629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.315500</td>\n",
              "      <td>0.492438</td>\n",
              "      <td>0.824830</td>\n",
              "      <td>0.824830</td>\n",
              "      <td>0.830256</td>\n",
              "      <td>0.824251</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 14:45:37,195] Trial 1 finished with value: 0.8242508162255248 and parameters: {'dropout_rate': 0.2601565286051022, 'learning_rate': 6.889419379185033e-06, 'weight_decay': 0.021888930141063547, 'warmup_ratio': 0.09088017994300641, 'lr_scheduler_type': 'polynomial', 'label_smoothing_factor': 0.022847670010059044, 'per_device_train_batch_size': 16, 'gradient_accumulation_steps': 1, 'num_train_epochs': 5}. Best is trial 0 with value: 0.8500601029968764.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3090' max='3090' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3090/3090 04:48, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.855800</td>\n",
              "      <td>0.823495</td>\n",
              "      <td>0.637634</td>\n",
              "      <td>0.637634</td>\n",
              "      <td>0.647592</td>\n",
              "      <td>0.630204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.572100</td>\n",
              "      <td>0.669736</td>\n",
              "      <td>0.692663</td>\n",
              "      <td>0.692663</td>\n",
              "      <td>0.701203</td>\n",
              "      <td>0.688722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.475900</td>\n",
              "      <td>0.535255</td>\n",
              "      <td>0.775146</td>\n",
              "      <td>0.775146</td>\n",
              "      <td>0.781812</td>\n",
              "      <td>0.772793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.402200</td>\n",
              "      <td>0.513849</td>\n",
              "      <td>0.790938</td>\n",
              "      <td>0.790938</td>\n",
              "      <td>0.796749</td>\n",
              "      <td>0.788871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.335700</td>\n",
              "      <td>0.486308</td>\n",
              "      <td>0.812318</td>\n",
              "      <td>0.812318</td>\n",
              "      <td>0.818155</td>\n",
              "      <td>0.811330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.309000</td>\n",
              "      <td>0.485550</td>\n",
              "      <td>0.813290</td>\n",
              "      <td>0.813290</td>\n",
              "      <td>0.819209</td>\n",
              "      <td>0.812235</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 14:50:29,697] Trial 2 finished with value: 0.8122353803697941 and parameters: {'dropout_rate': 0.26855450054306995, 'learning_rate': 9.072227988256057e-06, 'weight_decay': 0.04640459640554107, 'warmup_ratio': 0.051157609312498034, 'lr_scheduler_type': 'cosine', 'label_smoothing_factor': 0.0018513780402735502, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 2, 'num_train_epochs': 6}. Best is trial 0 with value: 0.8500601029968764.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8232' max='8232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8232/8232 06:54, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.045800</td>\n",
              "      <td>1.060154</td>\n",
              "      <td>0.499879</td>\n",
              "      <td>0.499879</td>\n",
              "      <td>0.507760</td>\n",
              "      <td>0.480664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.866732</td>\n",
              "      <td>0.602770</td>\n",
              "      <td>0.602770</td>\n",
              "      <td>0.612538</td>\n",
              "      <td>0.593060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.808700</td>\n",
              "      <td>0.804616</td>\n",
              "      <td>0.644679</td>\n",
              "      <td>0.644679</td>\n",
              "      <td>0.655543</td>\n",
              "      <td>0.635674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.784000</td>\n",
              "      <td>0.796823</td>\n",
              "      <td>0.649417</td>\n",
              "      <td>0.649417</td>\n",
              "      <td>0.660189</td>\n",
              "      <td>0.642092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 14:57:28,116] Trial 3 finished with value: 0.6420919165303793 and parameters: {'dropout_rate': 0.23052058422724836, 'learning_rate': 2.031435692797258e-06, 'weight_decay': 0.04967366251944675, 'warmup_ratio': 0.10328330559109605, 'lr_scheduler_type': 'cosine', 'label_smoothing_factor': 0.004781639562371431, 'per_device_train_batch_size': 16, 'gradient_accumulation_steps': 1, 'num_train_epochs': 4}. Best is trial 0 with value: 0.8500601029968764.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10290' max='10290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10290/10290 08:39, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.780500</td>\n",
              "      <td>0.795536</td>\n",
              "      <td>0.644436</td>\n",
              "      <td>0.644436</td>\n",
              "      <td>0.655384</td>\n",
              "      <td>0.637321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.652500</td>\n",
              "      <td>0.620033</td>\n",
              "      <td>0.730807</td>\n",
              "      <td>0.730807</td>\n",
              "      <td>0.738483</td>\n",
              "      <td>0.727596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.476200</td>\n",
              "      <td>0.559464</td>\n",
              "      <td>0.771866</td>\n",
              "      <td>0.771866</td>\n",
              "      <td>0.780062</td>\n",
              "      <td>0.769972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.447200</td>\n",
              "      <td>0.551571</td>\n",
              "      <td>0.780491</td>\n",
              "      <td>0.780491</td>\n",
              "      <td>0.787179</td>\n",
              "      <td>0.778772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.426200</td>\n",
              "      <td>0.522263</td>\n",
              "      <td>0.798712</td>\n",
              "      <td>0.798712</td>\n",
              "      <td>0.804812</td>\n",
              "      <td>0.797898</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 15:06:11,029] Trial 4 finished with value: 0.7978979162552914 and parameters: {'dropout_rate': 0.269737162202409, 'learning_rate': 4.656820012097027e-06, 'weight_decay': 0.010177176251660182, 'warmup_ratio': 0.039033568833094195, 'lr_scheduler_type': 'polynomial', 'label_smoothing_factor': 0.04205080805610029, 'per_device_train_batch_size': 16, 'gradient_accumulation_steps': 1, 'num_train_epochs': 5}. Best is trial 0 with value: 0.8500601029968764.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2575' max='2575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2575/2575 04:01, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.637100</td>\n",
              "      <td>0.566431</td>\n",
              "      <td>0.765914</td>\n",
              "      <td>0.765914</td>\n",
              "      <td>0.772558</td>\n",
              "      <td>0.764545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.382600</td>\n",
              "      <td>0.430592</td>\n",
              "      <td>0.830661</td>\n",
              "      <td>0.830661</td>\n",
              "      <td>0.835520</td>\n",
              "      <td>0.830051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.268700</td>\n",
              "      <td>0.407879</td>\n",
              "      <td>0.845603</td>\n",
              "      <td>0.845603</td>\n",
              "      <td>0.851141</td>\n",
              "      <td>0.845215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.196200</td>\n",
              "      <td>0.403480</td>\n",
              "      <td>0.861638</td>\n",
              "      <td>0.861638</td>\n",
              "      <td>0.865807</td>\n",
              "      <td>0.861366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.128900</td>\n",
              "      <td>0.431665</td>\n",
              "      <td>0.864553</td>\n",
              "      <td>0.864553</td>\n",
              "      <td>0.868007</td>\n",
              "      <td>0.864137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 15:10:16,177] Trial 5 finished with value: 0.8641369893117598 and parameters: {'dropout_rate': 0.2865670526897861, 'learning_rate': 2.8733099125303974e-05, 'weight_decay': 0.03372794162847042, 'warmup_ratio': 0.10484600696210584, 'lr_scheduler_type': 'polynomial', 'label_smoothing_factor': 0.07500897194550044, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 2, 'num_train_epochs': 5}. Best is trial 5 with value: 0.8641369893117598.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10290' max='10290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10290/10290 08:35, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.513500</td>\n",
              "      <td>0.462509</td>\n",
              "      <td>0.808552</td>\n",
              "      <td>0.808552</td>\n",
              "      <td>0.814331</td>\n",
              "      <td>0.807493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.370700</td>\n",
              "      <td>0.388767</td>\n",
              "      <td>0.866740</td>\n",
              "      <td>0.866740</td>\n",
              "      <td>0.870779</td>\n",
              "      <td>0.867229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.205800</td>\n",
              "      <td>0.419359</td>\n",
              "      <td>0.876215</td>\n",
              "      <td>0.876215</td>\n",
              "      <td>0.879661</td>\n",
              "      <td>0.876175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.136700</td>\n",
              "      <td>0.516601</td>\n",
              "      <td>0.875486</td>\n",
              "      <td>0.875486</td>\n",
              "      <td>0.878225</td>\n",
              "      <td>0.875137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.099400</td>\n",
              "      <td>0.545082</td>\n",
              "      <td>0.878887</td>\n",
              "      <td>0.878887</td>\n",
              "      <td>0.881511</td>\n",
              "      <td>0.878621</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 15:18:55,304] Trial 6 finished with value: 0.8786209676643522 and parameters: {'dropout_rate': 0.20147500177114858, 'learning_rate': 2.822654358378865e-05, 'weight_decay': 0.04764646836240873, 'warmup_ratio': 0.055229571653822265, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.04010405757714713, 'per_device_train_batch_size': 16, 'gradient_accumulation_steps': 1, 'num_train_epochs': 5}. Best is trial 6 with value: 0.8786209676643522.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5145' max='5145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5145/5145 04:26, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.982100</td>\n",
              "      <td>0.945274</td>\n",
              "      <td>0.563411</td>\n",
              "      <td>0.563411</td>\n",
              "      <td>0.571555</td>\n",
              "      <td>0.547048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.825400</td>\n",
              "      <td>0.808088</td>\n",
              "      <td>0.629009</td>\n",
              "      <td>0.629009</td>\n",
              "      <td>0.638261</td>\n",
              "      <td>0.619759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.713500</td>\n",
              "      <td>0.725428</td>\n",
              "      <td>0.682580</td>\n",
              "      <td>0.682580</td>\n",
              "      <td>0.692395</td>\n",
              "      <td>0.675025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.647400</td>\n",
              "      <td>0.699786</td>\n",
              "      <td>0.698008</td>\n",
              "      <td>0.698008</td>\n",
              "      <td>0.707760</td>\n",
              "      <td>0.691865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.620300</td>\n",
              "      <td>0.695179</td>\n",
              "      <td>0.700073</td>\n",
              "      <td>0.700073</td>\n",
              "      <td>0.709989</td>\n",
              "      <td>0.694977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 15:23:25,223] Trial 7 finished with value: 0.6949768328227813 and parameters: {'dropout_rate': 0.11751962613547272, 'learning_rate': 3.0056377536126184e-06, 'weight_decay': 0.03242600458894853, 'warmup_ratio': 0.006696160810086855, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.00440957560702552, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 1, 'num_train_epochs': 5}. Best is trial 6 with value: 0.8786209676643522.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4116' max='4116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4116/4116 06:15, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.464200</td>\n",
              "      <td>0.428251</td>\n",
              "      <td>0.827867</td>\n",
              "      <td>0.827867</td>\n",
              "      <td>0.833085</td>\n",
              "      <td>0.827231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.340600</td>\n",
              "      <td>0.378284</td>\n",
              "      <td>0.857264</td>\n",
              "      <td>0.857264</td>\n",
              "      <td>0.862537</td>\n",
              "      <td>0.857284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.196800</td>\n",
              "      <td>0.403342</td>\n",
              "      <td>0.871113</td>\n",
              "      <td>0.871113</td>\n",
              "      <td>0.875119</td>\n",
              "      <td>0.870864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.104200</td>\n",
              "      <td>0.428486</td>\n",
              "      <td>0.877308</td>\n",
              "      <td>0.877308</td>\n",
              "      <td>0.880449</td>\n",
              "      <td>0.876937</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 15:29:44,375] Trial 8 finished with value: 0.8769372180296435 and parameters: {'dropout_rate': 0.11026647641633446, 'learning_rate': 3.9364106348651224e-05, 'weight_decay': 0.034664203457956844, 'warmup_ratio': 7.623518486925107e-05, 'lr_scheduler_type': 'polynomial', 'label_smoothing_factor': 0.00032049189812171974, 'per_device_train_batch_size': 16, 'gradient_accumulation_steps': 2, 'num_train_epochs': 4}. Best is trial 6 with value: 0.8786209676643522.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6174' max='6174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6174/6174 05:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.633000</td>\n",
              "      <td>0.578423</td>\n",
              "      <td>0.749757</td>\n",
              "      <td>0.749757</td>\n",
              "      <td>0.757447</td>\n",
              "      <td>0.747622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.416100</td>\n",
              "      <td>0.412121</td>\n",
              "      <td>0.841351</td>\n",
              "      <td>0.841351</td>\n",
              "      <td>0.846084</td>\n",
              "      <td>0.841289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.278100</td>\n",
              "      <td>0.414618</td>\n",
              "      <td>0.843294</td>\n",
              "      <td>0.843294</td>\n",
              "      <td>0.848457</td>\n",
              "      <td>0.842803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.174900</td>\n",
              "      <td>0.434323</td>\n",
              "      <td>0.858965</td>\n",
              "      <td>0.858965</td>\n",
              "      <td>0.862015</td>\n",
              "      <td>0.858521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.128800</td>\n",
              "      <td>0.469353</td>\n",
              "      <td>0.866861</td>\n",
              "      <td>0.866861</td>\n",
              "      <td>0.870297</td>\n",
              "      <td>0.866451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.107700</td>\n",
              "      <td>0.483007</td>\n",
              "      <td>0.869534</td>\n",
              "      <td>0.869534</td>\n",
              "      <td>0.872558</td>\n",
              "      <td>0.869156</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 15:35:07,698] Trial 9 finished with value: 0.869155695770409 and parameters: {'dropout_rate': 0.18696534006792664, 'learning_rate': 2.008319902502594e-05, 'weight_decay': 0.04381996471332153, 'warmup_ratio': 0.09964882321610896, 'lr_scheduler_type': 'cosine', 'label_smoothing_factor': 0.0648161360575859, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 1, 'num_train_epochs': 6}. Best is trial 6 with value: 0.8786209676643522.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4116' max='4116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4116/4116 06:15, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.607400</td>\n",
              "      <td>0.600711</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.746093</td>\n",
              "      <td>0.734941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.434800</td>\n",
              "      <td>0.426938</td>\n",
              "      <td>0.824344</td>\n",
              "      <td>0.824344</td>\n",
              "      <td>0.830264</td>\n",
              "      <td>0.823435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.282800</td>\n",
              "      <td>0.408289</td>\n",
              "      <td>0.847182</td>\n",
              "      <td>0.847182</td>\n",
              "      <td>0.851970</td>\n",
              "      <td>0.846845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.202900</td>\n",
              "      <td>0.425393</td>\n",
              "      <td>0.848397</td>\n",
              "      <td>0.848397</td>\n",
              "      <td>0.852402</td>\n",
              "      <td>0.848034</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 15:41:26,470] Trial 10 finished with value: 0.8480337722283079 and parameters: {'dropout_rate': 0.21879857695457067, 'learning_rate': 1.694162061791463e-05, 'weight_decay': 0.00944463560487644, 'warmup_ratio': 0.06460012947649503, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.03251370641594824, 'per_device_train_batch_size': 16, 'gradient_accumulation_steps': 2, 'num_train_epochs': 4}. Best is trial 6 with value: 0.8786209676643522.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4116' max='4116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4116/4116 06:14, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.469800</td>\n",
              "      <td>0.437142</td>\n",
              "      <td>0.818999</td>\n",
              "      <td>0.818999</td>\n",
              "      <td>0.825111</td>\n",
              "      <td>0.818006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.337200</td>\n",
              "      <td>0.341585</td>\n",
              "      <td>0.868926</td>\n",
              "      <td>0.868926</td>\n",
              "      <td>0.873734</td>\n",
              "      <td>0.868822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.167200</td>\n",
              "      <td>0.397408</td>\n",
              "      <td>0.871477</td>\n",
              "      <td>0.871477</td>\n",
              "      <td>0.875452</td>\n",
              "      <td>0.871186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.086700</td>\n",
              "      <td>0.448042</td>\n",
              "      <td>0.876093</td>\n",
              "      <td>0.876093</td>\n",
              "      <td>0.879132</td>\n",
              "      <td>0.875718</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-12 15:47:44,779] Trial 11 finished with value: 0.8757176842038468 and parameters: {'dropout_rate': 0.11210729697348276, 'learning_rate': 4.6698588825345266e-05, 'weight_decay': 0.021806778101538145, 'warmup_ratio': 0.007822977020193009, 'lr_scheduler_type': 'linear', 'label_smoothing_factor': 0.04445989760275212, 'per_device_train_batch_size': 16, 'gradient_accumulation_steps': 2, 'num_train_epochs': 4}. Best is trial 6 with value: 0.8786209676643522.\n",
            "======= Tuning finished: stage1_broad | best f1_weighted=0.8786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16709' max='24696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16709/24696 13:56 < 06:39, 19.98 it/s, Epoch 8.12/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.576500</td>\n",
              "      <td>0.526952</td>\n",
              "      <td>0.773810</td>\n",
              "      <td>0.773810</td>\n",
              "      <td>0.780436</td>\n",
              "      <td>0.771543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.417600</td>\n",
              "      <td>0.385047</td>\n",
              "      <td>0.847911</td>\n",
              "      <td>0.847911</td>\n",
              "      <td>0.851361</td>\n",
              "      <td>0.847980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.304500</td>\n",
              "      <td>0.414542</td>\n",
              "      <td>0.854349</td>\n",
              "      <td>0.854349</td>\n",
              "      <td>0.857423</td>\n",
              "      <td>0.854491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.237600</td>\n",
              "      <td>0.477445</td>\n",
              "      <td>0.849976</td>\n",
              "      <td>0.849976</td>\n",
              "      <td>0.854778</td>\n",
              "      <td>0.849791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.187100</td>\n",
              "      <td>0.526061</td>\n",
              "      <td>0.871963</td>\n",
              "      <td>0.871963</td>\n",
              "      <td>0.875574</td>\n",
              "      <td>0.872007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.120300</td>\n",
              "      <td>0.582362</td>\n",
              "      <td>0.875486</td>\n",
              "      <td>0.875486</td>\n",
              "      <td>0.878297</td>\n",
              "      <td>0.875277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.146100</td>\n",
              "      <td>0.625834</td>\n",
              "      <td>0.873299</td>\n",
              "      <td>0.873299</td>\n",
              "      <td>0.876559</td>\n",
              "      <td>0.872710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.107800</td>\n",
              "      <td>0.710395</td>\n",
              "      <td>0.876944</td>\n",
              "      <td>0.876944</td>\n",
              "      <td>0.879629</td>\n",
              "      <td>0.876727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ========================================\n",
        "# 12) Fresh run (Stage 1): tune → final → save weights to Drive\n",
        "#     - Change N_TRIALS if you want more/less\n",
        "# ========================================\n",
        "N_TRIALS = 12\n",
        "best_params_s1, best_val_s1 = tune_once(\n",
        "    config_name=\"stage1_broad\",\n",
        "    search_space_fn=search_space_stage1,\n",
        "    n_trials=N_TRIALS,\n",
        "    tune_epochs=(4,6)\n",
        ")\n",
        "\n",
        "save_path_s1, val_metrics_s1, test_metrics_s1 = final_train_and_save(\n",
        "    config_name=\"stage1_broad\",\n",
        "    best_params=best_params_s1,\n",
        "    final_epochs=12,\n",
        "    save_name=\"HF_best_model_stage1.pt\"\n",
        ")\n",
        "\n",
        "print(\"Stage 1 — Validation:\", val_metrics_s1)\n",
        "print(\"Stage 1 — Test:\", test_metrics_s1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stage 2 – Hyperparameter narrowing: what we changed and why\n",
        "\n",
        "Learning rate → 2.6e-5–4.8e-5. Stage 1’s best runs clustered around ~2.8e-5/3.9e-5/4.7e-5. Narrowing here cuts unproductive very-low/very-high LRs while keeping the proven region.\n",
        "\n",
        "Dropout → 0.10–0.22. Top results used ~0.11–0.20. This range preserves enough regularization without over-penalizing the classifier head.\n",
        "\n",
        "Weight decay → 0.020–0.050. Winners sat around ~0.022–0.048. This protects pretrained representations while still damping overfitting.\n",
        "\n",
        "Warmup ratio → 0.00–0.08. Best trials included both ~0 and ~0.055; a small band keeps early training stable without slowing convergence.\n",
        "\n",
        "Scheduler → {linear, cosine_with_restarts}. These were the most consistently strong/steady in Stage 1; we removed less reliable options to focus search.\n",
        "\n",
        "Batch size → 16 (fixed) + GA ∈ {1,2}. Matches the strongest configs and allows adjusting effective batch size via accumulation.\n",
        "\n",
        "Num epochs → 4–6. Aligns with where validation peaks typically appeared in Stage 1 while keeping tuning time reasonable.\n",
        "\n",
        "Label smoothing → 0.00–0.05. Small amounts helped calibration; larger values tended to depress F1.\n",
        "\n",
        "Everything else unchanged. We still use class-weighted CE, macro/weighted F1 for selection/reporting, gradient clipping, early stopping, and saving only the best state_dict."
      ],
      "metadata": {
        "id": "Rj2vDu4jOa5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_space_stage2(trial, tune_epochs):\n",
        "    return {\n",
        "        \"dropout_rate\": trial.suggest_float(\"dropout_rate\", 0.10, 0.22),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2.6e-5, 4.8e-5, log=True),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.020, 0.050),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.00, 0.08),\n",
        "        \"lr_scheduler_type\": trial.suggest_categorical(\"lr_scheduler_type\", [\"linear\", \"cosine_with_restarts\"]),\n",
        "        \"label_smoothing_factor\": trial.suggest_float(\"label_smoothing_factor\", 0.00, 0.05),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16]),\n",
        "        \"gradient_accumulation_steps\": trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2]),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 4, 6),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "OJy3BLAKKfRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# 12) Fresh run (Stage 2): tune → final → save weights to Drive\n",
        "#     - Change N_TRIALS if you want more/less\n",
        "# ========================================\n",
        "N_TRIALS = 12\n",
        "best_params_s2, best_val_s2 = tune_once(\n",
        "    config_name=\"stage2_broad\",\n",
        "    search_space_fn=search_space_stage2,\n",
        "    n_trials=N_TRIALS,\n",
        "    tune_epochs=(4,6)\n",
        ")\n",
        "\n",
        "save_path_s2, val_metrics_s2, test_metrics_s2 = final_train_and_save(\n",
        "    config_name=\"stage1_broad\",\n",
        "    best_params=best_params_s2,\n",
        "    final_epochs=12,\n",
        "    save_name=\"HF_best_model_stage2.pt\"\n",
        ")\n",
        "\n",
        "print(\"Stage 2 — Validation:\", val_metrics_s2)\n",
        "print(\"Stage 2 — Test:\", test_metrics_s2)\n"
      ],
      "metadata": {
        "id": "QtIq9hetOEr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 2 Results**\n",
        "\n",
        "Validation (F1-macro): 0.8763\n",
        "\n",
        "Test (F1-macro): 0.8589\n",
        "\n",
        "Convergence: strong scores reached rapidly (≈ epoch 8), consistent with Stage 1’s early peaks.\n",
        "\n",
        "**Motivation for Stage 3 — Evidence-Driven Adjustments**\n",
        "\n",
        "The fast convergence in Stages 1–2 indicates that upper Transformer layers adapt quickly, while pushing lower layers too aggressively early can erode pretrained representations. Stage 3 therefore refines optimization mechanics to protect the backbone during the initial updates while still allowing the head/upper layers to adapt.\n",
        "\n",
        "**Optimizer Strategy Revision — Discriminative Learning Rates (DLR)**\n",
        "\n",
        "What changed: Introduced get_layer_id and build_param_groups to apply layer-wise LR decay (e.g., layer_decay ≈ 0.90).\n",
        "\n",
        "Why: Lower (earlier) encoder layers receive smaller LR to preserve general linguistic features learned during pretraining; upper layers and the classifier head retain the base LR to capture task-specific signals quickly.\n",
        "\n",
        "Mechanics: per-layer LR = base_lr * (layer_decay ** distance_from_top).\n",
        "\n",
        "**Early-Training Stabilization — Non-Zero Warmup**\n",
        "\n",
        "What changed: Enforced non-zero warmup by searching warmup_ratio ∈ [0.04, 0.12].\n",
        "\n",
        "Why: Stages 1–2 already showed early performance peaks; a modest warmup tempers the first optimization steps, reducing instability and catastrophic forgetting when LR is relatively high.\n",
        "\n",
        "**Search Space Configuration — Broad, Sane, and Grounded in Stage 2**\n",
        "\n",
        "Learning rate: 2e-5–5e-5 (log scale) — classic BERT band that covered Stage-2 winners while trimming unproductive extremes.\n",
        "\n",
        "Dropout: 0.10–0.30 — maintains effective regularization without over-penalizing the classifier.\n",
        "\n",
        "Weight decay: 0.00–0.05 — protects pretrained representations while still damping overfitting.\n",
        "\n",
        "Label smoothing: 0.00–0.08 — small values were sufficient in Stage 1–2.\n",
        "\n",
        "Scheduler options: {linear, cosine, cosine_with_restarts, polynomial} — retained to let tuning reaffirm the stable families observed in Stage 2.\n",
        "\n",
        "Batching: {16, 32} with GA ∈ {1, 2} — controls effective batch size without altering the data pipeline.\n",
        "\n",
        "Epoch range: inherited from tuning bounds used in Stage 2 to keep runs efficient and comparable.\n",
        "\n",
        "Class-weighted cross-entropy and macro-F1 remain the selection/reporting baseline to address label imbalance.\n",
        "\n",
        "Gradient clipping and a lightweight BestWeightsSaver continue to ensure stability and minimal I/O (saving only the best state_dict)."
      ],
      "metadata": {
        "id": "Vst2NbXoQ10N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvAbyNG-c5EC"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_layer_id(name: str) -> int:\n",
        "    \"\"\"\n",
        "    Map a parameter name to a layer id:\n",
        "    - embeddings -> 0\n",
        "    - encoder.layer.X -> X + 1\n",
        "    - pooler / classifier head -> last layer bucket (13)\n",
        "    \"\"\"\n",
        "    if name.startswith(\"bert.embeddings\"):\n",
        "        return 0\n",
        "    m = re.search(r\"bert\\.encoder\\.layer\\.(\\d+)\\.\", name)\n",
        "    if m:\n",
        "        return int(m.group(1)) + 1\n",
        "    # pooler / classifier head\n",
        "    return 13  # BERT-base has 12 encoder layers; 13 is the pooler/head bucket\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8aameihc8TK"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "def build_param_groups(model, base_lr, weight_decay, layer_decay=0.9):\n",
        "    \"\"\"\n",
        "    Create optimizer parameter groups with layer-wise learning-rate decay.\n",
        "\n",
        "    Notes:\n",
        "    - If layer_decay < 1.0, lower (earlier) layers learn more slowly than higher ones.\n",
        "    - base_lr is applied to the top bucket; lower buckets get base_lr * layer_decay^(distance).\n",
        "    \"\"\"\n",
        "    num_layers = 14  # ids 0..13 as returned by get_layer_id\n",
        "    # Parameters excluded from weight decay\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\", \"layer_norm.weight\", \"layer_norm.bias\"]\n",
        "\n",
        "    param_groups = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if not param.requires_grad:\n",
        "            continue\n",
        "        layer_id = get_layer_id(name)\n",
        "        # Per-layer LR: base_lr * (layer_decay ** (num_layers - layer_id - 1))\n",
        "        lr = base_lr * (layer_decay ** (num_layers - layer_id - 1))\n",
        "        use_decay = not any(nd in name for nd in no_decay)\n",
        "        key = (layer_id, use_decay)\n",
        "        if key not in param_groups:\n",
        "            param_groups[key] = {\n",
        "                \"params\": [],\n",
        "                \"lr\": lr,\n",
        "                \"weight_decay\": (weight_decay if use_decay else 0.0),\n",
        "            }\n",
        "        param_groups[key][\"params\"].append(param)\n",
        "    return list(param_groups.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqbPaGJuVFMq"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 9) Trainer factory (no HF checkpoints) + BestWeightsSaver callback\n",
        "#    - Discriminative LRs (layer-wise decay) + explicit scheduler\n",
        "#    - Saves ONLY best weights (state_dict) to a temp .pt\n",
        "#    - EarlyStopping uses eval_f1_weighted from compute_metrics_fn\n",
        "# ========================================\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "import torch\n",
        "import types\n",
        "from datetime import datetime\n",
        "from torch.optim import AdamW\n",
        "from transformers import (\n",
        "    TrainingArguments, Trainer, EarlyStoppingCallback, TrainerCallback, get_scheduler\n",
        ")\n",
        "\n",
        "class BestWeightsSaver(TrainerCallback):\n",
        "    \"\"\"\n",
        "    When 'eval_f1_weighted' improves, save ONLY model.state_dict() to `best_weights_path`.\n",
        "    \"\"\"\n",
        "    def __init__(self, best_weights_path: str, metric_name: str = \"eval_f1_weighted\"):\n",
        "        self.best_weights_path = best_weights_path\n",
        "        self.metric_name = metric_name\n",
        "        self.best_score = None\n",
        "        self._trainer = None  # injected on attach\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "        if not metrics or self.metric_name not in metrics:\n",
        "            return\n",
        "        score = float(metrics[self.metric_name])\n",
        "        if (self.best_score is None) or (score > self.best_score):\n",
        "            self.best_score = score\n",
        "            torch.save(self._trainer.model.state_dict(), self.best_weights_path)\n",
        "\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "\n",
        "# ---------- Helpers for discriminative learning rates ----------\n",
        "def get_layer_id(name: str) -> int:\n",
        "    \"\"\"\n",
        "    Map parameter name to a layer id:\n",
        "      - embeddings -> 0\n",
        "      - encoder.layer.X -> X+1  (X in [0..11] for BERT-base) => 1..12\n",
        "      - pooler / classifier head -> 13\n",
        "    \"\"\"\n",
        "    if name.startswith(\"bert.embeddings\"):\n",
        "        return 0\n",
        "    m = re.search(r\"bert\\.encoder\\.layer\\.(\\d+)\\.\", name)\n",
        "    if m:\n",
        "        return int(m.group(1)) + 1\n",
        "    return 13  # pooler/head\n",
        "\n",
        "def build_param_groups(model, base_lr: float, weight_decay: float, layer_decay: float = 0.90):\n",
        "    \"\"\"\n",
        "    Create optimizer param groups with layer-wise LR decay.\n",
        "    Lower layers get smaller LR; higher layers get larger LR.\n",
        "    \"\"\"\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\", \"layer_norm.weight\", \"layer_norm.bias\"]\n",
        "    num_layers = 14  # ids: 0..13\n",
        "    buckets = {}\n",
        "    for name, param in model.named_parameters():\n",
        "        if not param.requires_grad:\n",
        "            continue\n",
        "        lid = get_layer_id(name)\n",
        "        lr = base_lr * (layer_decay ** (num_layers - lid - 1))\n",
        "        use_decay = not any(nd in name for nd in no_decay)\n",
        "        key = (lid, use_decay)\n",
        "        if key not in buckets:\n",
        "            buckets[key] = {\n",
        "                \"params\": [],\n",
        "                \"lr\": lr,\n",
        "                \"weight_decay\": (weight_decay if use_decay else 0.0),\n",
        "            }\n",
        "        buckets[key][\"params\"].append(param)\n",
        "    return list(buckets.values())\n",
        "\n",
        "def make_trainer(\n",
        "    output_dir,\n",
        "    dropout_rate=0.2,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.08,                  # stronger warmup by default\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=1,\n",
        "    label_smoothing_factor=0.0,\n",
        "    fp16=True,\n",
        "    report_to_wandb=False,\n",
        "    run_name=\"trial\",\n",
        "    best_weights_path=\"/tmp/best_weights.pt\",\n",
        "    layer_decay=0.90,                   # LR decay factor across layers (0.85–0.95 typical)\n",
        "):\n",
        "    # Build model with the custom head\n",
        "    model = BertWithDropout(\n",
        "        model_name=MODEL_NAME,\n",
        "        num_labels=len(ordered_labels),\n",
        "        dropout_rate=dropout_rate,\n",
        "    )\n",
        "\n",
        "    # TrainingArguments: keep HF checkpoints off; early stopping driven by metrics\n",
        "    args = TrainingArguments(\n",
        "        output_dir=output_dir,                 # keep under /tmp to avoid Drive writes\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",                    # no HF checkpoints\n",
        "        load_best_model_at_end=False,          # best is handled by BestWeightsSaver\n",
        "        metric_for_best_model=\"f1_weighted\",\n",
        "        greater_is_better=True,\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=50,\n",
        "        per_device_train_batch_size=per_device_train_batch_size,\n",
        "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        warmup_ratio=0.0,                      # overridden by explicit scheduler below\n",
        "        learning_rate=learning_rate,           # base LR for the head/top layer\n",
        "        weight_decay=weight_decay,\n",
        "        lr_scheduler_type=\"linear\",            # unused by Trainer since we pass our own scheduler\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        label_smoothing_factor=label_smoothing_factor,\n",
        "        max_grad_norm=0.5,                     # gradient clipping\n",
        "        fp16=fp16,\n",
        "        report_to=([\"wandb\"] if report_to_wandb else [\"none\"]),\n",
        "        run_name=run_name,\n",
        "        seed=42,\n",
        "        dataloader_num_workers=2,\n",
        "    )\n",
        "\n",
        "    # Build discriminative LR optimizer\n",
        "    param_groups = build_param_groups(\n",
        "        model, base_lr=learning_rate, weight_decay=weight_decay, layer_decay=layer_decay\n",
        "    )\n",
        "    optimizer = AdamW(param_groups, betas=(0.9, 0.999), eps=1e-8)\n",
        "\n",
        "    # Compute total training steps and warmup steps for explicit scheduler\n",
        "    # Note: effective batch size accounts for gradient accumulation\n",
        "    effective_bs = per_device_train_batch_size * max(1, gradient_accumulation_steps)\n",
        "    num_update_steps_per_epoch = max(1, len(ds_tok[\"train\"]) // effective_bs)\n",
        "    num_training_steps = int(num_update_steps_per_epoch * num_train_epochs)\n",
        "    num_warmup_steps = int(warmup_ratio * num_training_steps)\n",
        "\n",
        "    lr_scheduler = get_scheduler(\n",
        "        name=lr_scheduler_type,                # \"linear\", \"cosine_with_restarts\", etc.\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=num_training_steps,\n",
        "    )\n",
        "\n",
        "    # Build Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=ds_tok[\"train\"],\n",
        "        eval_dataset=ds_tok[\"validation\"],\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics_fn,\n",
        "        optimizers=(optimizer, lr_scheduler),  # <-- pass our optimizer & scheduler\n",
        "    )\n",
        "\n",
        "    # Custom weighted CE loss (device-aware)\n",
        "    trainer.compute_loss = types.MethodType(custom_compute_loss, trainer)\n",
        "\n",
        "    # Early stopping (small patience keeps it agile)\n",
        "    trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=2))\n",
        "\n",
        "    # Attach best-weights saver\n",
        "    best_cb = BestWeightsSaver(best_weights_path=best_weights_path, metric_name=\"eval_f1_weighted\")\n",
        "    best_cb._trainer = trainer\n",
        "    trainer.add_callback(best_cb)\n",
        "\n",
        "    return trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFM5bP8heTHm"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 10) Generic experiment runner (replaces your old \"part 10\")\n",
        "#     - tune_once(): Optuna tuning for a given search space\n",
        "#     - final_train_and_save(): long-ish final run + save ONLY weights to Drive\n",
        "# ========================================\n",
        "import json\n",
        "import optuna\n",
        "import pandas as pd\n",
        "\n",
        "MODEL_DIR  =data_dir\n",
        "EXPERIMENTS_LOG = os.path.join(MODEL_DIR, \"HF_experiments_log_3b.csv\")  # append-only CSV\n",
        "\n",
        "def now_tag():\n",
        "    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "def temp_paths(tag: str):\n",
        "    stamp = now_tag()\n",
        "    out_dir = f\"/tmp/{tag}_{stamp}\"\n",
        "    best_pt = f\"/tmp/{tag}_{stamp}_best.pt\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    return out_dir, best_pt\n",
        "\n",
        "def append_row_to_log(row: dict):\n",
        "    if os.path.exists(EXPERIMENTS_LOG):\n",
        "        df = pd.read_csv(EXPERIMENTS_LOG)\n",
        "        df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "    else:\n",
        "        df = pd.DataFrame([row])\n",
        "    df.to_csv(EXPERIMENTS_LOG, index=False)\n",
        "\n",
        "def tune_once(config_name: str, search_space_fn, n_trials=10, tune_epochs=(3,6)):\n",
        "    \"\"\"\n",
        "    Run Optuna on a provided search space function.\n",
        "    Returns (best_params, best_value).\n",
        "    \"\"\"\n",
        "    def objective(trial: optuna.trial.Trial):\n",
        "        hp = search_space_fn(trial, tune_epochs)\n",
        "        out_dir, best_pt = temp_paths(f\"tune_{config_name}_t{trial.number}\")\n",
        "        trainer = make_trainer(\n",
        "            output_dir=out_dir,\n",
        "            dropout_rate=hp[\"dropout_rate\"],\n",
        "            learning_rate=hp[\"learning_rate\"],\n",
        "            weight_decay=hp[\"weight_decay\"],\n",
        "            warmup_ratio=hp[\"warmup_ratio\"],\n",
        "            lr_scheduler_type=hp[\"lr_scheduler_type\"],\n",
        "            per_device_train_batch_size=hp[\"per_device_train_batch_size\"],\n",
        "            per_device_eval_batch_size=64,\n",
        "            num_train_epochs=hp[\"num_train_epochs\"],\n",
        "            gradient_accumulation_steps=hp[\"gradient_accumulation_steps\"],\n",
        "            label_smoothing_factor=hp[\"label_smoothing_factor\"],\n",
        "            layer_decay=hp[\"layer_decay\"],\n",
        "            fp16=True,\n",
        "            report_to_wandb=False,\n",
        "            run_name=f\"{config_name}-trial-{trial.number}\",\n",
        "            best_weights_path=best_pt\n",
        "        )\n",
        "        trainer.train()\n",
        "        metrics = trainer.evaluate(ds_tok[\"validation\"])\n",
        "        score = float(metrics.get(\"eval_f1_weighted\") or metrics.get(\"f1_weighted\") or 0.0)\n",
        "\n",
        "        # Clean temp\n",
        "        try:\n",
        "            if os.path.exists(best_pt):\n",
        "                os.remove(best_pt)\n",
        "        except OSError:\n",
        "            pass\n",
        "        del trainer\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "        return score\n",
        "\n",
        "    study_name = f\"{config_name}_{now_tag()}\"\n",
        "    study = optuna.create_study(direction=\"maximize\", study_name=study_name)\n",
        "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
        "\n",
        "    # log summary\n",
        "    row = {\n",
        "        \"time\": now_tag(),\n",
        "        \"phase\": \"tuning\",\n",
        "        \"config\": config_name,\n",
        "        \"study_name\": study_name,\n",
        "        \"best_value_f1w\": study.best_value,\n",
        "        \"best_params_json\": json.dumps(study.best_trial.params, ensure_ascii=False),\n",
        "        \"n_trials\": n_trials,\n",
        "        \"tune_epochs\": str(tune_epochs),\n",
        "    }\n",
        "    append_row_to_log(row)\n",
        "    print(f\"======= Tuning finished: {config_name} | best f1_weighted={study.best_value:.4f}\")\n",
        "    return study.best_trial.params, study.best_value\n",
        "\n",
        "def final_train_and_save(config_name: str, best_params: dict, final_epochs=12, save_name=None):\n",
        "    \"\"\"\n",
        "    Final training with best params (longer, ES active), save ONLY weights .pt to Drive,\n",
        "    log val/test to CSV.\n",
        "    \"\"\"\n",
        "    out_dir, best_pt = temp_paths(f\"final_{config_name}\")\n",
        "    trainer = make_trainer(\n",
        "        output_dir=out_dir,\n",
        "        dropout_rate=best_params.get(\"dropout_rate\", 0.2),\n",
        "        learning_rate=best_params.get(\"learning_rate\", 2e-5),\n",
        "        weight_decay=best_params.get(\"weight_decay\", 0.01),\n",
        "        warmup_ratio=best_params.get(\"warmup_ratio\", 0.06),\n",
        "        lr_scheduler_type=best_params.get(\"lr_scheduler_type\", \"linear\"),\n",
        "        per_device_train_batch_size=best_params.get(\"per_device_train_batch_size\", 32),\n",
        "        per_device_eval_batch_size=64,\n",
        "        num_train_epochs=final_epochs,\n",
        "        gradient_accumulation_steps=best_params.get(\"gradient_accumulation_steps\", 1),\n",
        "        label_smoothing_factor=best_params.get(\"label_smoothing_factor\", 0.0),\n",
        "        fp16=True,\n",
        "        report_to_wandb=False,\n",
        "        run_name=f\"{config_name}-final\",\n",
        "        best_weights_path=best_pt\n",
        "    )\n",
        "    trainer.train()\n",
        "    val_metrics  = trainer.evaluate(ds_tok[\"validation\"])\n",
        "    test_metrics = trainer.evaluate(ds_tok[\"test\"])\n",
        "\n",
        "    # Rebuild and save ONLY weights to Drive\n",
        "    model_for_save = BertWithDropout(\n",
        "        model_name=MODEL_NAME,\n",
        "        num_labels=len(ordered_labels),\n",
        "        dropout_rate=best_params.get(\"dropout_rate\", 0.2),\n",
        "    )\n",
        "    assert os.path.exists(best_pt), \"Temp best weights not found.\"\n",
        "    model_for_save.load_state_dict(torch.load(best_pt, map_location=\"cpu\"))\n",
        "\n",
        "    if save_name is None:\n",
        "        save_name = f\"HF_best_{config_name}_{now_tag()}.pt\"\n",
        "    drive_path = os.path.join(MODEL_DIR, save_name)\n",
        "    torch.save(model_for_save.state_dict(), drive_path)\n",
        "    print(f\"========= Final best weights saved to: {drive_path}\")\n",
        "\n",
        "    # cleanup temp\n",
        "    try:\n",
        "        os.remove(best_pt)\n",
        "    except OSError:\n",
        "        pass\n",
        "    del trainer, model_for_save\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    # append final results\n",
        "    row = {\n",
        "        \"time\": now_tag(),\n",
        "        \"phase\": \"final\",\n",
        "        \"config\": config_name,\n",
        "        \"val_f1_weighted\": float(val_metrics.get(\"eval_f1_weighted\", 0.0)),\n",
        "        \"val_accuracy\": float(val_metrics.get(\"eval_accuracy\", 0.0)),\n",
        "        \"test_f1_weighted\": float(test_metrics.get(\"eval_f1_weighted\", 0.0)),\n",
        "        \"test_accuracy\": float(test_metrics.get(\"eval_accuracy\", 0.0)),\n",
        "        \"saved_to\": drive_path,\n",
        "    }\n",
        "    append_row_to_log(row)\n",
        "    return drive_path, val_metrics, test_metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxGTeCjcffNx"
      },
      "outputs": [],
      "source": [
        "def search_space_stage3(trial, tune_epochs):\n",
        "    return {\n",
        "        \"dropout_rate\": trial.suggest_float(\"dropout_rate\", 0.10, 0.30),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 5e-5, log=True),   # narrower & effective\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.00, 0.05),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.04, 0.12),               # no zero-warmup\n",
        "        \"lr_scheduler_type\": trial.suggest_categorical(\n",
        "            \"lr_scheduler_type\", [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\"]\n",
        "        ),\n",
        "        \"label_smoothing_factor\": trial.suggest_float(\"label_smoothing_factor\", 0.00, 0.08),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32]),\n",
        "        \"gradient_accumulation_steps\": trial.suggest_categorical(\"gradient_accumulation_steps\", [1, 2]),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", tune_epochs[0], tune_epochs[1]),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "194cdc198a9a47378651b68c85efbf37",
            "5a2216f93d1a454b99695b3f0a79687a",
            "3cb9ba69052d485dab0e4726daea215d",
            "0cbe3879ff58474aa9460ae8ee19894c",
            "6ad7c9ac909b44e1903182ab0c072860",
            "c0b3be77f0084c88b14ed4664e8a6b8f",
            "b8b857824ff945fa89d7a80e241384db",
            "bb7793a3904046ccab6e30631c4fe936",
            "a2a80fa80c934968837832494a5b00a8",
            "ab7cab50472d45489e4eb550756b20ff",
            "294d397714ac4e77958f445f768f78f2"
          ]
        },
        "id": "vIS85ShGffHX",
        "outputId": "0dd8e3a3-2394-4423-ebcf-747e163fa857"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 08:56:41,150] A new study created in memory with name: stage3_broad_20250813_085641\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "194cdc198a9a47378651b68c85efbf37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3090' max='3090' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3090/3090 04:45, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.723600</td>\n",
              "      <td>0.614806</td>\n",
              "      <td>0.751822</td>\n",
              "      <td>0.751822</td>\n",
              "      <td>0.760999</td>\n",
              "      <td>0.750810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.408300</td>\n",
              "      <td>0.441492</td>\n",
              "      <td>0.826895</td>\n",
              "      <td>0.826895</td>\n",
              "      <td>0.833389</td>\n",
              "      <td>0.826286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.297800</td>\n",
              "      <td>0.400215</td>\n",
              "      <td>0.847303</td>\n",
              "      <td>0.847303</td>\n",
              "      <td>0.852721</td>\n",
              "      <td>0.847300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.221100</td>\n",
              "      <td>0.415122</td>\n",
              "      <td>0.851798</td>\n",
              "      <td>0.851798</td>\n",
              "      <td>0.856496</td>\n",
              "      <td>0.851328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.153800</td>\n",
              "      <td>0.439108</td>\n",
              "      <td>0.856778</td>\n",
              "      <td>0.856778</td>\n",
              "      <td>0.860399</td>\n",
              "      <td>0.856263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.120200</td>\n",
              "      <td>0.436310</td>\n",
              "      <td>0.860787</td>\n",
              "      <td>0.860787</td>\n",
              "      <td>0.864290</td>\n",
              "      <td>0.860402</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:01:31,841] Trial 0 finished with value: 0.8604021607335369 and parameters: {'dropout_rate': 0.15595333678907414, 'learning_rate': 2.1701780299161078e-05, 'weight_decay': 0.044137549166471716, 'warmup_ratio': 0.10265306726055529, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.05363132769093291, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 2, 'num_train_epochs': 6}. Best is trial 0 with value: 0.8604021607335369.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2575' max='2575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2575/2575 03:58, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.570700</td>\n",
              "      <td>0.528729</td>\n",
              "      <td>0.764699</td>\n",
              "      <td>0.764699</td>\n",
              "      <td>0.770769</td>\n",
              "      <td>0.763524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.328800</td>\n",
              "      <td>0.375595</td>\n",
              "      <td>0.850705</td>\n",
              "      <td>0.850705</td>\n",
              "      <td>0.855757</td>\n",
              "      <td>0.850299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.213900</td>\n",
              "      <td>0.380553</td>\n",
              "      <td>0.860909</td>\n",
              "      <td>0.860909</td>\n",
              "      <td>0.865084</td>\n",
              "      <td>0.860571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.151400</td>\n",
              "      <td>0.434973</td>\n",
              "      <td>0.855807</td>\n",
              "      <td>0.855807</td>\n",
              "      <td>0.859334</td>\n",
              "      <td>0.855152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.080300</td>\n",
              "      <td>0.445989</td>\n",
              "      <td>0.874271</td>\n",
              "      <td>0.874271</td>\n",
              "      <td>0.877011</td>\n",
              "      <td>0.873880</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:05:34,550] Trial 1 finished with value: 0.8738801188863231 and parameters: {'dropout_rate': 0.2418584697681444, 'learning_rate': 4.5426123419405116e-05, 'weight_decay': 0.02260490512465817, 'warmup_ratio': 0.057842448969637306, 'lr_scheduler_type': 'polynomial', 'label_smoothing_factor': 0.04797308931649804, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 2, 'num_train_epochs': 5}. Best is trial 1 with value: 0.8738801188863231.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3090' max='3090' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3090/3090 04:49, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.598300</td>\n",
              "      <td>0.567925</td>\n",
              "      <td>0.748664</td>\n",
              "      <td>0.748664</td>\n",
              "      <td>0.755533</td>\n",
              "      <td>0.747616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.351900</td>\n",
              "      <td>0.412439</td>\n",
              "      <td>0.834913</td>\n",
              "      <td>0.834913</td>\n",
              "      <td>0.839775</td>\n",
              "      <td>0.834323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.235900</td>\n",
              "      <td>0.379736</td>\n",
              "      <td>0.858601</td>\n",
              "      <td>0.858601</td>\n",
              "      <td>0.863575</td>\n",
              "      <td>0.858356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.155900</td>\n",
              "      <td>0.408767</td>\n",
              "      <td>0.870748</td>\n",
              "      <td>0.870748</td>\n",
              "      <td>0.873463</td>\n",
              "      <td>0.870407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.085500</td>\n",
              "      <td>0.471110</td>\n",
              "      <td>0.872813</td>\n",
              "      <td>0.872813</td>\n",
              "      <td>0.875707</td>\n",
              "      <td>0.872311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.054100</td>\n",
              "      <td>0.482206</td>\n",
              "      <td>0.877672</td>\n",
              "      <td>0.877672</td>\n",
              "      <td>0.880094</td>\n",
              "      <td>0.877354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:10:27,762] Trial 2 finished with value: 0.8773542278694372 and parameters: {'dropout_rate': 0.14326237856625343, 'learning_rate': 4.363186753680259e-05, 'weight_decay': 0.03568254360304753, 'warmup_ratio': 0.10737934160792925, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.05443869433588054, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 2, 'num_train_epochs': 6}. Best is trial 2 with value: 0.8773542278694372.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5145' max='5145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5145/5145 04:24, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.562400</td>\n",
              "      <td>0.520551</td>\n",
              "      <td>0.772230</td>\n",
              "      <td>0.772230</td>\n",
              "      <td>0.779308</td>\n",
              "      <td>0.769642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.363100</td>\n",
              "      <td>0.398729</td>\n",
              "      <td>0.845724</td>\n",
              "      <td>0.845724</td>\n",
              "      <td>0.849874</td>\n",
              "      <td>0.845643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.213200</td>\n",
              "      <td>0.388435</td>\n",
              "      <td>0.862002</td>\n",
              "      <td>0.862002</td>\n",
              "      <td>0.866118</td>\n",
              "      <td>0.861939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.132700</td>\n",
              "      <td>0.442772</td>\n",
              "      <td>0.867711</td>\n",
              "      <td>0.867711</td>\n",
              "      <td>0.870518</td>\n",
              "      <td>0.867329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.097800</td>\n",
              "      <td>0.471337</td>\n",
              "      <td>0.869776</td>\n",
              "      <td>0.869776</td>\n",
              "      <td>0.872655</td>\n",
              "      <td>0.869401</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:14:56,091] Trial 3 finished with value: 0.8694011848777663 and parameters: {'dropout_rate': 0.15933968840994384, 'learning_rate': 2.555145402680631e-05, 'weight_decay': 0.037230437506689223, 'warmup_ratio': 0.04573287079951783, 'lr_scheduler_type': 'cosine', 'label_smoothing_factor': 0.05623650232863429, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 1, 'num_train_epochs': 5}. Best is trial 2 with value: 0.8773542278694372.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5145' max='5145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5145/5145 04:25, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.515200</td>\n",
              "      <td>0.451922</td>\n",
              "      <td>0.817298</td>\n",
              "      <td>0.817298</td>\n",
              "      <td>0.822641</td>\n",
              "      <td>0.816655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.345000</td>\n",
              "      <td>0.363137</td>\n",
              "      <td>0.857629</td>\n",
              "      <td>0.857629</td>\n",
              "      <td>0.860910</td>\n",
              "      <td>0.857841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.198900</td>\n",
              "      <td>0.414711</td>\n",
              "      <td>0.853499</td>\n",
              "      <td>0.853499</td>\n",
              "      <td>0.857079</td>\n",
              "      <td>0.853043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.118500</td>\n",
              "      <td>0.461030</td>\n",
              "      <td>0.874879</td>\n",
              "      <td>0.874879</td>\n",
              "      <td>0.878325</td>\n",
              "      <td>0.874895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.074500</td>\n",
              "      <td>0.540708</td>\n",
              "      <td>0.879981</td>\n",
              "      <td>0.879981</td>\n",
              "      <td>0.882820</td>\n",
              "      <td>0.879700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:19:25,365] Trial 4 finished with value: 0.8796995329659303 and parameters: {'dropout_rate': 0.2061438312114165, 'learning_rate': 4.274295366982027e-05, 'weight_decay': 0.03712185367062346, 'warmup_ratio': 0.06635320311649105, 'lr_scheduler_type': 'polynomial', 'label_smoothing_factor': 0.059603308405046844, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 1, 'num_train_epochs': 5}. Best is trial 4 with value: 0.8796995329659303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6174' max='6174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6174/6174 05:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.532700</td>\n",
              "      <td>0.486701</td>\n",
              "      <td>0.793975</td>\n",
              "      <td>0.793975</td>\n",
              "      <td>0.800119</td>\n",
              "      <td>0.792796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.355400</td>\n",
              "      <td>0.383321</td>\n",
              "      <td>0.849490</td>\n",
              "      <td>0.849490</td>\n",
              "      <td>0.853907</td>\n",
              "      <td>0.849460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.221900</td>\n",
              "      <td>0.389285</td>\n",
              "      <td>0.858358</td>\n",
              "      <td>0.858358</td>\n",
              "      <td>0.861889</td>\n",
              "      <td>0.858344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.125800</td>\n",
              "      <td>0.520216</td>\n",
              "      <td>0.853256</td>\n",
              "      <td>0.853256</td>\n",
              "      <td>0.856064</td>\n",
              "      <td>0.852813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.115200</td>\n",
              "      <td>0.537361</td>\n",
              "      <td>0.869655</td>\n",
              "      <td>0.869655</td>\n",
              "      <td>0.872684</td>\n",
              "      <td>0.869374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.091200</td>\n",
              "      <td>0.605464</td>\n",
              "      <td>0.871113</td>\n",
              "      <td>0.871113</td>\n",
              "      <td>0.873648</td>\n",
              "      <td>0.870640</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:24:48,746] Trial 5 finished with value: 0.8706401033327335 and parameters: {'dropout_rate': 0.1212905977671946, 'learning_rate': 3.0752534719068916e-05, 'weight_decay': 0.00384391180014122, 'warmup_ratio': 0.04446636778882403, 'lr_scheduler_type': 'polynomial', 'label_smoothing_factor': 0.010846405151715359, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 1, 'num_train_epochs': 6}. Best is trial 4 with value: 0.8796995329659303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4116' max='4116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4116/4116 06:14, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.516400</td>\n",
              "      <td>0.513409</td>\n",
              "      <td>0.791424</td>\n",
              "      <td>0.791424</td>\n",
              "      <td>0.799881</td>\n",
              "      <td>0.790264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.357024</td>\n",
              "      <td>0.862002</td>\n",
              "      <td>0.862002</td>\n",
              "      <td>0.866390</td>\n",
              "      <td>0.861825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.193900</td>\n",
              "      <td>0.371005</td>\n",
              "      <td>0.874393</td>\n",
              "      <td>0.874393</td>\n",
              "      <td>0.878180</td>\n",
              "      <td>0.874244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.108000</td>\n",
              "      <td>0.438734</td>\n",
              "      <td>0.873664</td>\n",
              "      <td>0.873664</td>\n",
              "      <td>0.876772</td>\n",
              "      <td>0.873285</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:31:06,950] Trial 6 finished with value: 0.8732847862894614 and parameters: {'dropout_rate': 0.13251176442979082, 'learning_rate': 4.277566273079183e-05, 'weight_decay': 0.0282017187682237, 'warmup_ratio': 0.09927349167367046, 'lr_scheduler_type': 'polynomial', 'label_smoothing_factor': 0.05981395731945376, 'per_device_train_batch_size': 16, 'gradient_accumulation_steps': 2, 'num_train_epochs': 4}. Best is trial 4 with value: 0.8796995329659303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2575' max='2575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2575/2575 04:02, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.671700</td>\n",
              "      <td>0.589882</td>\n",
              "      <td>0.756924</td>\n",
              "      <td>0.756924</td>\n",
              "      <td>0.765221</td>\n",
              "      <td>0.756158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.388300</td>\n",
              "      <td>0.424918</td>\n",
              "      <td>0.832362</td>\n",
              "      <td>0.832362</td>\n",
              "      <td>0.837935</td>\n",
              "      <td>0.831831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.278000</td>\n",
              "      <td>0.400788</td>\n",
              "      <td>0.845117</td>\n",
              "      <td>0.845117</td>\n",
              "      <td>0.850434</td>\n",
              "      <td>0.844888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.204600</td>\n",
              "      <td>0.415853</td>\n",
              "      <td>0.854835</td>\n",
              "      <td>0.854835</td>\n",
              "      <td>0.858832</td>\n",
              "      <td>0.854591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.137700</td>\n",
              "      <td>0.432003</td>\n",
              "      <td>0.861638</td>\n",
              "      <td>0.861638</td>\n",
              "      <td>0.865110</td>\n",
              "      <td>0.861364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:35:13,425] Trial 7 finished with value: 0.8613642642230006 and parameters: {'dropout_rate': 0.12637393659197935, 'learning_rate': 2.5860949960576632e-05, 'weight_decay': 0.029903745018725808, 'warmup_ratio': 0.11472570246140434, 'lr_scheduler_type': 'polynomial', 'label_smoothing_factor': 0.0036284201134994198, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 2, 'num_train_epochs': 5}. Best is trial 4 with value: 0.8796995329659303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4116' max='4116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4116/4116 03:31, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.494300</td>\n",
              "      <td>0.453657</td>\n",
              "      <td>0.806973</td>\n",
              "      <td>0.806973</td>\n",
              "      <td>0.811415</td>\n",
              "      <td>0.805858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.332900</td>\n",
              "      <td>0.355016</td>\n",
              "      <td>0.863946</td>\n",
              "      <td>0.863946</td>\n",
              "      <td>0.867848</td>\n",
              "      <td>0.864067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.187900</td>\n",
              "      <td>0.397112</td>\n",
              "      <td>0.864674</td>\n",
              "      <td>0.864674</td>\n",
              "      <td>0.868515</td>\n",
              "      <td>0.864309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.095500</td>\n",
              "      <td>0.447201</td>\n",
              "      <td>0.877551</td>\n",
              "      <td>0.877551</td>\n",
              "      <td>0.880372</td>\n",
              "      <td>0.877285</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:38:49,148] Trial 8 finished with value: 0.8772852126414277 and parameters: {'dropout_rate': 0.12668372895220825, 'learning_rate': 4.459642456147132e-05, 'weight_decay': 0.026295873004453747, 'warmup_ratio': 0.061022928052223036, 'lr_scheduler_type': 'linear', 'label_smoothing_factor': 0.03606827502376737, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 1, 'num_train_epochs': 4}. Best is trial 4 with value: 0.8796995329659303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6174' max='6174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6174/6174 05:17, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.611900</td>\n",
              "      <td>0.560133</td>\n",
              "      <td>0.762391</td>\n",
              "      <td>0.762391</td>\n",
              "      <td>0.770238</td>\n",
              "      <td>0.760634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.410200</td>\n",
              "      <td>0.400546</td>\n",
              "      <td>0.844266</td>\n",
              "      <td>0.844266</td>\n",
              "      <td>0.849324</td>\n",
              "      <td>0.844191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.263200</td>\n",
              "      <td>0.415746</td>\n",
              "      <td>0.845845</td>\n",
              "      <td>0.845845</td>\n",
              "      <td>0.851194</td>\n",
              "      <td>0.845484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.158200</td>\n",
              "      <td>0.434986</td>\n",
              "      <td>0.858479</td>\n",
              "      <td>0.858479</td>\n",
              "      <td>0.861605</td>\n",
              "      <td>0.858009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.112900</td>\n",
              "      <td>0.492343</td>\n",
              "      <td>0.869412</td>\n",
              "      <td>0.869412</td>\n",
              "      <td>0.872882</td>\n",
              "      <td>0.868961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.094500</td>\n",
              "      <td>0.508858</td>\n",
              "      <td>0.874028</td>\n",
              "      <td>0.874028</td>\n",
              "      <td>0.876950</td>\n",
              "      <td>0.873694</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:44:10,482] Trial 9 finished with value: 0.8736941298338812 and parameters: {'dropout_rate': 0.2093747597471573, 'learning_rate': 2.412813209242847e-05, 'weight_decay': 0.04899071512358802, 'warmup_ratio': 0.11313682629160365, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.06647659161705205, 'per_device_train_batch_size': 32, 'gradient_accumulation_steps': 1, 'num_train_epochs': 6}. Best is trial 4 with value: 0.8796995329659303.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7548' max='8232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7548/8232 06:12 < 00:33, 20.24 it/s, Epoch 3.67/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.512400</td>\n",
              "      <td>0.469758</td>\n",
              "      <td>0.805151</td>\n",
              "      <td>0.805151</td>\n",
              "      <td>0.812206</td>\n",
              "      <td>0.804188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.358700</td>\n",
              "      <td>0.378330</td>\n",
              "      <td>0.865525</td>\n",
              "      <td>0.865525</td>\n",
              "      <td>0.870271</td>\n",
              "      <td>0.866039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.192100</td>\n",
              "      <td>0.466367</td>\n",
              "      <td>0.874150</td>\n",
              "      <td>0.874150</td>\n",
              "      <td>0.877367</td>\n",
              "      <td>0.873934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8232' max='8232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8232/8232 06:49, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.512400</td>\n",
              "      <td>0.469758</td>\n",
              "      <td>0.805151</td>\n",
              "      <td>0.805151</td>\n",
              "      <td>0.812206</td>\n",
              "      <td>0.804188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.358700</td>\n",
              "      <td>0.378330</td>\n",
              "      <td>0.865525</td>\n",
              "      <td>0.865525</td>\n",
              "      <td>0.870271</td>\n",
              "      <td>0.866039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.192100</td>\n",
              "      <td>0.466367</td>\n",
              "      <td>0.874150</td>\n",
              "      <td>0.874150</td>\n",
              "      <td>0.877367</td>\n",
              "      <td>0.873934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.143500</td>\n",
              "      <td>0.527549</td>\n",
              "      <td>0.879981</td>\n",
              "      <td>0.879981</td>\n",
              "      <td>0.882685</td>\n",
              "      <td>0.879803</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:51:03,526] Trial 10 finished with value: 0.879803077483344 and parameters: {'dropout_rate': 0.2988315295555632, 'learning_rate': 3.474121708630032e-05, 'weight_decay': 0.014321964825734085, 'warmup_ratio': 0.08188839233811213, 'lr_scheduler_type': 'cosine', 'label_smoothing_factor': 0.07576920509762469, 'per_device_train_batch_size': 16, 'gradient_accumulation_steps': 1, 'num_train_epochs': 4}. Best is trial 10 with value: 0.879803077483344.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8232' max='8232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8232/8232 06:55, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.520800</td>\n",
              "      <td>0.470885</td>\n",
              "      <td>0.801749</td>\n",
              "      <td>0.801749</td>\n",
              "      <td>0.808603</td>\n",
              "      <td>0.800482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.353300</td>\n",
              "      <td>0.431047</td>\n",
              "      <td>0.848397</td>\n",
              "      <td>0.848397</td>\n",
              "      <td>0.851065</td>\n",
              "      <td>0.848306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.187900</td>\n",
              "      <td>0.478019</td>\n",
              "      <td>0.874271</td>\n",
              "      <td>0.874271</td>\n",
              "      <td>0.877952</td>\n",
              "      <td>0.874094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.135200</td>\n",
              "      <td>0.549288</td>\n",
              "      <td>0.881560</td>\n",
              "      <td>0.881560</td>\n",
              "      <td>0.884313</td>\n",
              "      <td>0.881375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-13 09:58:02,459] Trial 11 finished with value: 0.8813748459092184 and parameters: {'dropout_rate': 0.29529657837750006, 'learning_rate': 3.6074197197478196e-05, 'weight_decay': 0.013861334169702078, 'warmup_ratio': 0.08243887040342272, 'lr_scheduler_type': 'cosine', 'label_smoothing_factor': 0.07747124325253954, 'per_device_train_batch_size': 16, 'gradient_accumulation_steps': 1, 'num_train_epochs': 4}. Best is trial 11 with value: 0.8813748459092184.\n",
            "======= Tuning finished: stage3_broad | best f1_weighted=0.8814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24696' max='24696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24696/24696 20:48, Epoch 12/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.583900</td>\n",
              "      <td>0.600934</td>\n",
              "      <td>0.737366</td>\n",
              "      <td>0.737366</td>\n",
              "      <td>0.744489</td>\n",
              "      <td>0.734013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.434000</td>\n",
              "      <td>0.455987</td>\n",
              "      <td>0.834913</td>\n",
              "      <td>0.834913</td>\n",
              "      <td>0.838954</td>\n",
              "      <td>0.835694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.304900</td>\n",
              "      <td>0.411162</td>\n",
              "      <td>0.856050</td>\n",
              "      <td>0.856050</td>\n",
              "      <td>0.860470</td>\n",
              "      <td>0.855977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.246600</td>\n",
              "      <td>0.531000</td>\n",
              "      <td>0.828596</td>\n",
              "      <td>0.828596</td>\n",
              "      <td>0.836596</td>\n",
              "      <td>0.828459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.196500</td>\n",
              "      <td>0.708884</td>\n",
              "      <td>0.857264</td>\n",
              "      <td>0.857264</td>\n",
              "      <td>0.859665</td>\n",
              "      <td>0.856840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.169900</td>\n",
              "      <td>0.563529</td>\n",
              "      <td>0.871963</td>\n",
              "      <td>0.871963</td>\n",
              "      <td>0.875413</td>\n",
              "      <td>0.871656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.102800</td>\n",
              "      <td>0.674311</td>\n",
              "      <td>0.882046</td>\n",
              "      <td>0.882046</td>\n",
              "      <td>0.884167</td>\n",
              "      <td>0.881976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.084400</td>\n",
              "      <td>0.757486</td>\n",
              "      <td>0.882532</td>\n",
              "      <td>0.882532</td>\n",
              "      <td>0.884681</td>\n",
              "      <td>0.882452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.026900</td>\n",
              "      <td>0.766624</td>\n",
              "      <td>0.882532</td>\n",
              "      <td>0.882532</td>\n",
              "      <td>0.884833</td>\n",
              "      <td>0.882137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.028100</td>\n",
              "      <td>0.855928</td>\n",
              "      <td>0.884475</td>\n",
              "      <td>0.884475</td>\n",
              "      <td>0.887198</td>\n",
              "      <td>0.884369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.020200</td>\n",
              "      <td>0.872015</td>\n",
              "      <td>0.884840</td>\n",
              "      <td>0.884840</td>\n",
              "      <td>0.887404</td>\n",
              "      <td>0.884726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.882624</td>\n",
              "      <td>0.885204</td>\n",
              "      <td>0.885204</td>\n",
              "      <td>0.887719</td>\n",
              "      <td>0.885105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='189' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:03]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========= Final best weights saved to: /content/drive/MyDrive/deep_learning/HF_best_model_stage3.pt\n",
            "Stage 3 — Validation: {'eval_loss': 0.8826243281364441, 'eval_accuracy': 0.8852040816326531, 'eval_f1_micro': 0.8852040816326531, 'eval_f1_macro': 0.8877186499037657, 'eval_f1_weighted': 0.885104591068076, 'eval_runtime': 2.3346, 'eval_samples_per_second': 3526.098, 'eval_steps_per_second': 55.256, 'epoch': 12.0}\n",
            "Stage 3 — Test: {'eval_loss': 1.0449219942092896, 'eval_accuracy': 0.8622959452343338, 'eval_f1_micro': 0.8622959452343338, 'eval_f1_macro': 0.8643927270667865, 'eval_f1_weighted': 0.8626914491589446, 'eval_runtime': 1.2844, 'eval_samples_per_second': 2957.044, 'eval_steps_per_second': 46.715, 'epoch': 12.0}\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 12) Fresh run (Stage 3): tune → final → save weights to Drive\n",
        "#     - Change N_TRIALS if you want more/less\n",
        "# ========================================\n",
        "N_TRIALS = 12\n",
        "best_params_s3, best_val_s3 = tune_once(\n",
        "    config_name=\"stage3_broad\",\n",
        "    search_space_fn=search_space_stage3,\n",
        "    n_trials=N_TRIALS,\n",
        "    tune_epochs=(4,6)\n",
        ")\n",
        "\n",
        "save_path_s3, val_metrics_s3, test_metrics_s3 = final_train_and_save(\n",
        "    config_name=\"stage3_broad\",\n",
        "    best_params=best_params_s3,\n",
        "    final_epochs=12,\n",
        "    save_name=\"HF_best_model_stage3.pt\"\n",
        ")\n",
        "\n",
        "print(\"Stage 3 — Validation:\", val_metrics_s3)\n",
        "print(\"Stage 3 — Test:\", test_metrics_s3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 3 results**.\n",
        " After introducing Discriminative Learning Rates (layer-wise LR decay) and enforcing a non-zero warmup, performance improved modestly yet consistently: val F1-macro = 0.8877 and test F1-macro = 0.8644 (vs. Stage 2: 0.8763 / 0.8589). This aligns with the observation from Stages 1–2 that strong scores arrive early: protecting lower encoder layers while letting upper layers/head adapt faster yields slightly better generalization.\n",
        "\n",
        "Why Stage 3b. Based on Stage 3, we narrowed the search to the regime that worked best and exposed the DLR strength as a tunable hyperparameter:\n",
        "\n",
        "Learning rate 3.2e-5–4.2e-5 and dropout 0.14–0.22: centered around Stage-3 winners, balancing capacity and regularization.\n",
        "\n",
        "Weight decay 0.025–0.040: enough to curb overfitting without eroding pretrained features.\n",
        "\n",
        "Warmup ratio 0.06–0.10 with cosine_with_restarts: stabilizes the sensitive early steps under higher LR and supports smooth restarts.\n",
        "\n",
        "Label smoothing 0.01–0.04: mild calibration without depressing F1.\n",
        "\n",
        "Batch size 16, GA=1; epochs 6–9: practical budget that still gives sufficient post-warmup updates.\n",
        "\n",
        "layer_decay 0.88–0.94 (new): explicitly tunes how aggressively lower layers are slowed relative to the head, letting the search find the best preservation/adaptation trade-off for this dataset."
      ],
      "metadata": {
        "id": "OgyIgkZ6SmU1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54Kz8feGfe_v"
      },
      "outputs": [],
      "source": [
        "def search_space_stage3b(trial, tune_epochs):\n",
        "    return {\n",
        "        \"dropout_rate\": trial.suggest_float(\"dropout_rate\", 0.14, 0.22),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 3.2e-5, 4.2e-5, log=True),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.025, 0.040),\n",
        "        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.06, 0.10),\n",
        "        \"lr_scheduler_type\": trial.suggest_categorical(\"lr_scheduler_type\", [\"cosine_with_restarts\"]),\n",
        "        \"label_smoothing_factor\": trial.suggest_float(\"label_smoothing_factor\", 0.01, 0.04),\n",
        "        \"per_device_train_batch_size\": 16,\n",
        "        \"gradient_accumulation_steps\": trial.suggest_categorical(\"gradient_accumulation_steps\", [1]),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 6, 9),\n",
        "        \"layer_decay\": trial.suggest_float(\"layer_decay\", 0.88, 0.94),   # <— new\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "200d9ee2b8a240e189346384b121774f",
            "cf3dd87d73cf46da9e5560695c6b957e"
          ]
        },
        "id": "EBhpEHPGJajD",
        "outputId": "2b2de242-7e57-4c72-9cec-4f821d0e19ea"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 08:31:15,222] A new study created in memory with name: stage3_broad_20250816_083115\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "200d9ee2b8a240e189346384b121774f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf3dd87d73cf46da9e5560695c6b957e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16464' max='18522' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16464/18522 13:33 < 01:41, 20.23 it/s, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.542000</td>\n",
              "      <td>0.532396</td>\n",
              "      <td>0.779519</td>\n",
              "      <td>0.779519</td>\n",
              "      <td>0.785335</td>\n",
              "      <td>0.777809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.443800</td>\n",
              "      <td>0.396256</td>\n",
              "      <td>0.858601</td>\n",
              "      <td>0.858601</td>\n",
              "      <td>0.862638</td>\n",
              "      <td>0.858918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.287000</td>\n",
              "      <td>0.377104</td>\n",
              "      <td>0.871477</td>\n",
              "      <td>0.871477</td>\n",
              "      <td>0.875110</td>\n",
              "      <td>0.871215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.214000</td>\n",
              "      <td>0.512250</td>\n",
              "      <td>0.861516</td>\n",
              "      <td>0.861516</td>\n",
              "      <td>0.865888</td>\n",
              "      <td>0.861264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.221600</td>\n",
              "      <td>0.602413</td>\n",
              "      <td>0.871842</td>\n",
              "      <td>0.871842</td>\n",
              "      <td>0.875095</td>\n",
              "      <td>0.871774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.151300</td>\n",
              "      <td>0.647518</td>\n",
              "      <td>0.884232</td>\n",
              "      <td>0.884232</td>\n",
              "      <td>0.886910</td>\n",
              "      <td>0.884285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.077500</td>\n",
              "      <td>0.756742</td>\n",
              "      <td>0.873056</td>\n",
              "      <td>0.873056</td>\n",
              "      <td>0.875172</td>\n",
              "      <td>0.872377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.053000</td>\n",
              "      <td>0.786963</td>\n",
              "      <td>0.883989</td>\n",
              "      <td>0.883989</td>\n",
              "      <td>0.886705</td>\n",
              "      <td>0.883990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 08:44:55,600] Trial 0 finished with value: 0.8839900594867922 and parameters: {'dropout_rate': 0.16408942708279703, 'learning_rate': 3.61986288641032e-05, 'weight_decay': 0.028124189863572593, 'warmup_ratio': 0.08234885804435392, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.03137726175461909, 'gradient_accumulation_steps': 1, 'num_train_epochs': 9, 'layer_decay': 0.9245368698965649}. Best is trial 0 with value: 0.8839900594867922.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16464' max='18522' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16464/18522 13:39 < 01:42, 20.09 it/s, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.580100</td>\n",
              "      <td>0.661113</td>\n",
              "      <td>0.731171</td>\n",
              "      <td>0.731171</td>\n",
              "      <td>0.738784</td>\n",
              "      <td>0.730434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.461800</td>\n",
              "      <td>0.400624</td>\n",
              "      <td>0.848761</td>\n",
              "      <td>0.848761</td>\n",
              "      <td>0.852077</td>\n",
              "      <td>0.849056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.276100</td>\n",
              "      <td>0.468363</td>\n",
              "      <td>0.837828</td>\n",
              "      <td>0.837828</td>\n",
              "      <td>0.841763</td>\n",
              "      <td>0.837515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.267100</td>\n",
              "      <td>0.476004</td>\n",
              "      <td>0.869412</td>\n",
              "      <td>0.869412</td>\n",
              "      <td>0.872769</td>\n",
              "      <td>0.869514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.148700</td>\n",
              "      <td>0.579634</td>\n",
              "      <td>0.875729</td>\n",
              "      <td>0.875729</td>\n",
              "      <td>0.879463</td>\n",
              "      <td>0.875610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.122300</td>\n",
              "      <td>0.604023</td>\n",
              "      <td>0.883989</td>\n",
              "      <td>0.883989</td>\n",
              "      <td>0.886595</td>\n",
              "      <td>0.884046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.106400</td>\n",
              "      <td>0.698060</td>\n",
              "      <td>0.880831</td>\n",
              "      <td>0.880831</td>\n",
              "      <td>0.883548</td>\n",
              "      <td>0.880618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.056900</td>\n",
              "      <td>0.799089</td>\n",
              "      <td>0.879252</td>\n",
              "      <td>0.879252</td>\n",
              "      <td>0.882069</td>\n",
              "      <td>0.879121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 08:58:38,703] Trial 1 finished with value: 0.8791208561989817 and parameters: {'dropout_rate': 0.19534184097554932, 'learning_rate': 4.1162105249323976e-05, 'weight_decay': 0.039494262402305386, 'warmup_ratio': 0.09269565062535498, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.01576635931597327, 'gradient_accumulation_steps': 1, 'num_train_epochs': 9, 'layer_decay': 0.9105164114980139}. Best is trial 0 with value: 0.8839900594867922.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8232' max='16464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 8232/16464 06:50 < 06:50, 20.06 it/s, Epoch 4/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.548300</td>\n",
              "      <td>0.549407</td>\n",
              "      <td>0.755466</td>\n",
              "      <td>0.755466</td>\n",
              "      <td>0.762123</td>\n",
              "      <td>0.752076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.389300</td>\n",
              "      <td>0.389520</td>\n",
              "      <td>0.860180</td>\n",
              "      <td>0.860180</td>\n",
              "      <td>0.863827</td>\n",
              "      <td>0.860624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.276600</td>\n",
              "      <td>0.430801</td>\n",
              "      <td>0.858115</td>\n",
              "      <td>0.858115</td>\n",
              "      <td>0.861976</td>\n",
              "      <td>0.858134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.208200</td>\n",
              "      <td>0.543577</td>\n",
              "      <td>0.855078</td>\n",
              "      <td>0.855078</td>\n",
              "      <td>0.860462</td>\n",
              "      <td>0.855107</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 09:05:32,628] Trial 2 finished with value: 0.8551065200615596 and parameters: {'dropout_rate': 0.1523468653747467, 'learning_rate': 4.117270114735324e-05, 'weight_decay': 0.03455900111939162, 'warmup_ratio': 0.06806614024049087, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.010628502774788377, 'gradient_accumulation_steps': 1, 'num_train_epochs': 8, 'layer_decay': 0.9193443702987073}. Best is trial 0 with value: 0.8839900594867922.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16464' max='16464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16464/16464 13:43, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.537100</td>\n",
              "      <td>0.512400</td>\n",
              "      <td>0.784135</td>\n",
              "      <td>0.784135</td>\n",
              "      <td>0.788975</td>\n",
              "      <td>0.782468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.410100</td>\n",
              "      <td>0.402500</td>\n",
              "      <td>0.854835</td>\n",
              "      <td>0.854835</td>\n",
              "      <td>0.858550</td>\n",
              "      <td>0.855394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.239500</td>\n",
              "      <td>0.418450</td>\n",
              "      <td>0.866740</td>\n",
              "      <td>0.866740</td>\n",
              "      <td>0.870104</td>\n",
              "      <td>0.866917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.222200</td>\n",
              "      <td>0.563789</td>\n",
              "      <td>0.844145</td>\n",
              "      <td>0.844145</td>\n",
              "      <td>0.849482</td>\n",
              "      <td>0.843685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.155400</td>\n",
              "      <td>0.571335</td>\n",
              "      <td>0.882046</td>\n",
              "      <td>0.882046</td>\n",
              "      <td>0.884351</td>\n",
              "      <td>0.882056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.112200</td>\n",
              "      <td>0.657167</td>\n",
              "      <td>0.883139</td>\n",
              "      <td>0.883139</td>\n",
              "      <td>0.885338</td>\n",
              "      <td>0.883109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.079500</td>\n",
              "      <td>0.731126</td>\n",
              "      <td>0.882775</td>\n",
              "      <td>0.882775</td>\n",
              "      <td>0.885010</td>\n",
              "      <td>0.882663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.068000</td>\n",
              "      <td>0.746916</td>\n",
              "      <td>0.882896</td>\n",
              "      <td>0.882896</td>\n",
              "      <td>0.885042</td>\n",
              "      <td>0.882727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 09:19:20,142] Trial 3 finished with value: 0.8827272575851898 and parameters: {'dropout_rate': 0.16065073401418237, 'learning_rate': 3.261093131608964e-05, 'weight_decay': 0.039581840169171136, 'warmup_ratio': 0.07589678563201828, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.023417496679193572, 'gradient_accumulation_steps': 1, 'num_train_epochs': 8, 'layer_decay': 0.8994141266933808}. Best is trial 0 with value: 0.8839900594867922.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16464' max='16464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16464/16464 13:44, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.568500</td>\n",
              "      <td>0.594883</td>\n",
              "      <td>0.749271</td>\n",
              "      <td>0.749271</td>\n",
              "      <td>0.755203</td>\n",
              "      <td>0.748093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.439300</td>\n",
              "      <td>0.405899</td>\n",
              "      <td>0.846331</td>\n",
              "      <td>0.846331</td>\n",
              "      <td>0.850317</td>\n",
              "      <td>0.846842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.276900</td>\n",
              "      <td>0.463330</td>\n",
              "      <td>0.851433</td>\n",
              "      <td>0.851433</td>\n",
              "      <td>0.854730</td>\n",
              "      <td>0.851109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.211000</td>\n",
              "      <td>0.503915</td>\n",
              "      <td>0.860180</td>\n",
              "      <td>0.860180</td>\n",
              "      <td>0.865190</td>\n",
              "      <td>0.859810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.177400</td>\n",
              "      <td>0.614871</td>\n",
              "      <td>0.875364</td>\n",
              "      <td>0.875364</td>\n",
              "      <td>0.879207</td>\n",
              "      <td>0.875219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.101900</td>\n",
              "      <td>0.688423</td>\n",
              "      <td>0.881681</td>\n",
              "      <td>0.881681</td>\n",
              "      <td>0.884062</td>\n",
              "      <td>0.881597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.060200</td>\n",
              "      <td>0.735474</td>\n",
              "      <td>0.879616</td>\n",
              "      <td>0.879616</td>\n",
              "      <td>0.882195</td>\n",
              "      <td>0.879512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.045900</td>\n",
              "      <td>0.750587</td>\n",
              "      <td>0.880224</td>\n",
              "      <td>0.880224</td>\n",
              "      <td>0.882992</td>\n",
              "      <td>0.879978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 09:33:08,492] Trial 4 finished with value: 0.8799784769869495 and parameters: {'dropout_rate': 0.16798208091258596, 'learning_rate': 3.589677819326689e-05, 'weight_decay': 0.030435465022505916, 'warmup_ratio': 0.08888266628169948, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.029463806160141826, 'gradient_accumulation_steps': 1, 'num_train_epochs': 8, 'layer_decay': 0.9080020241714486}. Best is trial 0 with value: 0.8839900594867922.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8232' max='16464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 8232/16464 06:51 < 06:51, 20.00 it/s, Epoch 4/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.552400</td>\n",
              "      <td>0.485512</td>\n",
              "      <td>0.792517</td>\n",
              "      <td>0.792517</td>\n",
              "      <td>0.799640</td>\n",
              "      <td>0.791306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.405000</td>\n",
              "      <td>0.411814</td>\n",
              "      <td>0.851798</td>\n",
              "      <td>0.851798</td>\n",
              "      <td>0.855416</td>\n",
              "      <td>0.852264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.264200</td>\n",
              "      <td>0.445169</td>\n",
              "      <td>0.849004</td>\n",
              "      <td>0.849004</td>\n",
              "      <td>0.853115</td>\n",
              "      <td>0.848549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.226800</td>\n",
              "      <td>0.638799</td>\n",
              "      <td>0.824830</td>\n",
              "      <td>0.824830</td>\n",
              "      <td>0.831386</td>\n",
              "      <td>0.824155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 09:40:03,707] Trial 5 finished with value: 0.824154506053319 and parameters: {'dropout_rate': 0.15237908439080503, 'learning_rate': 3.544787587710216e-05, 'weight_decay': 0.026694000634427072, 'warmup_ratio': 0.06081654598219058, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.030211284345162938, 'gradient_accumulation_steps': 1, 'num_train_epochs': 8, 'layer_decay': 0.8868966448047284}. Best is trial 0 with value: 0.8839900594867922.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12348' max='12348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12348/12348 10:16, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.534500</td>\n",
              "      <td>0.461133</td>\n",
              "      <td>0.807216</td>\n",
              "      <td>0.807216</td>\n",
              "      <td>0.813134</td>\n",
              "      <td>0.806010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.401300</td>\n",
              "      <td>0.366789</td>\n",
              "      <td>0.863460</td>\n",
              "      <td>0.863460</td>\n",
              "      <td>0.866955</td>\n",
              "      <td>0.863789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>0.444549</td>\n",
              "      <td>0.867468</td>\n",
              "      <td>0.867468</td>\n",
              "      <td>0.871082</td>\n",
              "      <td>0.867313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.198800</td>\n",
              "      <td>0.557653</td>\n",
              "      <td>0.872328</td>\n",
              "      <td>0.872328</td>\n",
              "      <td>0.875488</td>\n",
              "      <td>0.872300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.130800</td>\n",
              "      <td>0.660372</td>\n",
              "      <td>0.878037</td>\n",
              "      <td>0.878037</td>\n",
              "      <td>0.881131</td>\n",
              "      <td>0.877736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.112900</td>\n",
              "      <td>0.696345</td>\n",
              "      <td>0.878280</td>\n",
              "      <td>0.878280</td>\n",
              "      <td>0.881123</td>\n",
              "      <td>0.878013</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 09:50:24,156] Trial 6 finished with value: 0.8780125981049088 and parameters: {'dropout_rate': 0.16663188425483327, 'learning_rate': 3.349204795442046e-05, 'weight_decay': 0.029435634242650045, 'warmup_ratio': 0.06961563642517851, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.023832687699781904, 'gradient_accumulation_steps': 1, 'num_train_epochs': 6, 'layer_decay': 0.9247702716441539}. Best is trial 0 with value: 0.8839900594867922.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14406' max='16464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14406/16464 11:59 < 01:42, 20.01 it/s, Epoch 7/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.561300</td>\n",
              "      <td>0.564792</td>\n",
              "      <td>0.754130</td>\n",
              "      <td>0.754130</td>\n",
              "      <td>0.759992</td>\n",
              "      <td>0.752118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.442700</td>\n",
              "      <td>0.429270</td>\n",
              "      <td>0.839043</td>\n",
              "      <td>0.839043</td>\n",
              "      <td>0.842499</td>\n",
              "      <td>0.838997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.293500</td>\n",
              "      <td>0.470294</td>\n",
              "      <td>0.848761</td>\n",
              "      <td>0.848761</td>\n",
              "      <td>0.853597</td>\n",
              "      <td>0.848757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.264400</td>\n",
              "      <td>0.543154</td>\n",
              "      <td>0.861516</td>\n",
              "      <td>0.861516</td>\n",
              "      <td>0.865456</td>\n",
              "      <td>0.861327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.178900</td>\n",
              "      <td>0.536825</td>\n",
              "      <td>0.881924</td>\n",
              "      <td>0.881924</td>\n",
              "      <td>0.884781</td>\n",
              "      <td>0.881900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.137800</td>\n",
              "      <td>0.636264</td>\n",
              "      <td>0.880709</td>\n",
              "      <td>0.880709</td>\n",
              "      <td>0.883552</td>\n",
              "      <td>0.880580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.058200</td>\n",
              "      <td>0.771525</td>\n",
              "      <td>0.878158</td>\n",
              "      <td>0.878158</td>\n",
              "      <td>0.880886</td>\n",
              "      <td>0.878035</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 10:02:27,669] Trial 7 finished with value: 0.8780351312170656 and parameters: {'dropout_rate': 0.20084021911901953, 'learning_rate': 3.9976520267476336e-05, 'weight_decay': 0.028970175189628217, 'warmup_ratio': 0.07070548120655495, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.021891973405387948, 'gradient_accumulation_steps': 1, 'num_train_epochs': 8, 'layer_decay': 0.9304086031092185}. Best is trial 0 with value: 0.8839900594867922.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14406' max='14406' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14406/14406 11:59, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.541200</td>\n",
              "      <td>0.458379</td>\n",
              "      <td>0.812682</td>\n",
              "      <td>0.812682</td>\n",
              "      <td>0.817875</td>\n",
              "      <td>0.812507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.451200</td>\n",
              "      <td>0.369488</td>\n",
              "      <td>0.859329</td>\n",
              "      <td>0.859329</td>\n",
              "      <td>0.862800</td>\n",
              "      <td>0.859638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.221400</td>\n",
              "      <td>0.407245</td>\n",
              "      <td>0.866254</td>\n",
              "      <td>0.866254</td>\n",
              "      <td>0.870094</td>\n",
              "      <td>0.866563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.226000</td>\n",
              "      <td>0.530985</td>\n",
              "      <td>0.868440</td>\n",
              "      <td>0.868440</td>\n",
              "      <td>0.871933</td>\n",
              "      <td>0.868215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.140500</td>\n",
              "      <td>0.644140</td>\n",
              "      <td>0.881317</td>\n",
              "      <td>0.881317</td>\n",
              "      <td>0.884175</td>\n",
              "      <td>0.881449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.092600</td>\n",
              "      <td>0.708304</td>\n",
              "      <td>0.878523</td>\n",
              "      <td>0.878523</td>\n",
              "      <td>0.881282</td>\n",
              "      <td>0.878349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.046900</td>\n",
              "      <td>0.742380</td>\n",
              "      <td>0.878523</td>\n",
              "      <td>0.878523</td>\n",
              "      <td>0.881322</td>\n",
              "      <td>0.878297</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 10:14:31,147] Trial 8 finished with value: 0.8782974130126235 and parameters: {'dropout_rate': 0.1973000521691612, 'learning_rate': 3.93462197627553e-05, 'weight_decay': 0.032619780040069234, 'warmup_ratio': 0.06853458728511458, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.032220352985575205, 'gradient_accumulation_steps': 1, 'num_train_epochs': 7, 'layer_decay': 0.9182187044622494}. Best is trial 0 with value: 0.8839900594867922.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12348' max='12348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12348/12348 10:15, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.552100</td>\n",
              "      <td>0.472016</td>\n",
              "      <td>0.801142</td>\n",
              "      <td>0.801142</td>\n",
              "      <td>0.807174</td>\n",
              "      <td>0.799546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.406200</td>\n",
              "      <td>0.428778</td>\n",
              "      <td>0.842323</td>\n",
              "      <td>0.842323</td>\n",
              "      <td>0.845648</td>\n",
              "      <td>0.842936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.231400</td>\n",
              "      <td>0.445542</td>\n",
              "      <td>0.849125</td>\n",
              "      <td>0.849125</td>\n",
              "      <td>0.852682</td>\n",
              "      <td>0.848557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.200600</td>\n",
              "      <td>0.555868</td>\n",
              "      <td>0.866254</td>\n",
              "      <td>0.866254</td>\n",
              "      <td>0.870373</td>\n",
              "      <td>0.865898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.146100</td>\n",
              "      <td>0.618385</td>\n",
              "      <td>0.881195</td>\n",
              "      <td>0.881195</td>\n",
              "      <td>0.884244</td>\n",
              "      <td>0.880896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.091400</td>\n",
              "      <td>0.654392</td>\n",
              "      <td>0.879495</td>\n",
              "      <td>0.879495</td>\n",
              "      <td>0.882383</td>\n",
              "      <td>0.879278</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 10:24:50,885] Trial 9 finished with value: 0.8792781531560178 and parameters: {'dropout_rate': 0.19243504077217044, 'learning_rate': 3.274766879919058e-05, 'weight_decay': 0.03131002843253278, 'warmup_ratio': 0.08003191006349072, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.027873591488274313, 'gradient_accumulation_steps': 1, 'num_train_epochs': 6, 'layer_decay': 0.8929577495976786}. Best is trial 0 with value: 0.8839900594867922.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18522' max='18522' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18522/18522 15:24, Epoch 9/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.549100</td>\n",
              "      <td>0.661800</td>\n",
              "      <td>0.717809</td>\n",
              "      <td>0.717809</td>\n",
              "      <td>0.724432</td>\n",
              "      <td>0.714252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.422700</td>\n",
              "      <td>0.433619</td>\n",
              "      <td>0.851676</td>\n",
              "      <td>0.851676</td>\n",
              "      <td>0.855673</td>\n",
              "      <td>0.851967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.287300</td>\n",
              "      <td>0.408923</td>\n",
              "      <td>0.852770</td>\n",
              "      <td>0.852770</td>\n",
              "      <td>0.855743</td>\n",
              "      <td>0.852879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.249000</td>\n",
              "      <td>0.566964</td>\n",
              "      <td>0.848518</td>\n",
              "      <td>0.848518</td>\n",
              "      <td>0.853947</td>\n",
              "      <td>0.848058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.205300</td>\n",
              "      <td>0.550637</td>\n",
              "      <td>0.876093</td>\n",
              "      <td>0.876093</td>\n",
              "      <td>0.879532</td>\n",
              "      <td>0.876140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.133700</td>\n",
              "      <td>0.630962</td>\n",
              "      <td>0.878401</td>\n",
              "      <td>0.878401</td>\n",
              "      <td>0.881032</td>\n",
              "      <td>0.878106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.087300</td>\n",
              "      <td>0.704844</td>\n",
              "      <td>0.882896</td>\n",
              "      <td>0.882896</td>\n",
              "      <td>0.885676</td>\n",
              "      <td>0.882578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.067700</td>\n",
              "      <td>0.790756</td>\n",
              "      <td>0.881438</td>\n",
              "      <td>0.881438</td>\n",
              "      <td>0.883908</td>\n",
              "      <td>0.881180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.005200</td>\n",
              "      <td>0.819043</td>\n",
              "      <td>0.880588</td>\n",
              "      <td>0.880588</td>\n",
              "      <td>0.883110</td>\n",
              "      <td>0.880385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[I 2025-08-16 10:40:18,889] Trial 10 finished with value: 0.8803850771163517 and parameters: {'dropout_rate': 0.21918903000480222, 'learning_rate': 3.773146779683816e-05, 'weight_decay': 0.02523558953674387, 'warmup_ratio': 0.0847548244930056, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.03986436491869984, 'gradient_accumulation_steps': 1, 'num_train_epochs': 9, 'layer_decay': 0.9278713129217717}. Best is trial 0 with value: 0.8839900594867922.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6272' max='18522' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 6272/18522 05:12 < 10:11, 20.03 it/s, Epoch 3.05/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.565700</td>\n",
              "      <td>0.651515</td>\n",
              "      <td>0.715743</td>\n",
              "      <td>0.715743</td>\n",
              "      <td>0.722870</td>\n",
              "      <td>0.710955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.429900</td>\n",
              "      <td>0.432665</td>\n",
              "      <td>0.847425</td>\n",
              "      <td>0.847425</td>\n",
              "      <td>0.851879</td>\n",
              "      <td>0.847775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.292700</td>\n",
              "      <td>0.409695</td>\n",
              "      <td>0.862002</td>\n",
              "      <td>0.862002</td>\n",
              "      <td>0.865143</td>\n",
              "      <td>0.862364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18522' max='18522' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18522/18522 15:27, Epoch 9/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.565700</td>\n",
              "      <td>0.651515</td>\n",
              "      <td>0.715743</td>\n",
              "      <td>0.715743</td>\n",
              "      <td>0.722870</td>\n",
              "      <td>0.710955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.429900</td>\n",
              "      <td>0.432665</td>\n",
              "      <td>0.847425</td>\n",
              "      <td>0.847425</td>\n",
              "      <td>0.851879</td>\n",
              "      <td>0.847775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.292700</td>\n",
              "      <td>0.409695</td>\n",
              "      <td>0.862002</td>\n",
              "      <td>0.862002</td>\n",
              "      <td>0.865143</td>\n",
              "      <td>0.862364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.205100</td>\n",
              "      <td>0.517238</td>\n",
              "      <td>0.850826</td>\n",
              "      <td>0.850826</td>\n",
              "      <td>0.855060</td>\n",
              "      <td>0.850528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.179400</td>\n",
              "      <td>0.599170</td>\n",
              "      <td>0.866983</td>\n",
              "      <td>0.866983</td>\n",
              "      <td>0.870638</td>\n",
              "      <td>0.866610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.123900</td>\n",
              "      <td>0.648700</td>\n",
              "      <td>0.883989</td>\n",
              "      <td>0.883989</td>\n",
              "      <td>0.886566</td>\n",
              "      <td>0.883885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.093200</td>\n",
              "      <td>0.697095</td>\n",
              "      <td>0.879616</td>\n",
              "      <td>0.879616</td>\n",
              "      <td>0.882712</td>\n",
              "      <td>0.879159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.033800</td>\n",
              "      <td>0.771816</td>\n",
              "      <td>0.885326</td>\n",
              "      <td>0.885326</td>\n",
              "      <td>0.888181</td>\n",
              "      <td>0.885073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.027900</td>\n",
              "      <td>0.790443</td>\n",
              "      <td>0.887026</td>\n",
              "      <td>0.887026</td>\n",
              "      <td>0.889879</td>\n",
              "      <td>0.886891</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-08-16 10:55:50,182] Trial 11 finished with value: 0.8868905874305938 and parameters: {'dropout_rate': 0.14022414018100807, 'learning_rate': 3.424734557815674e-05, 'weight_decay': 0.03852529221309016, 'warmup_ratio': 0.09914937113184212, 'lr_scheduler_type': 'cosine_with_restarts', 'label_smoothing_factor': 0.036533919355799964, 'gradient_accumulation_steps': 1, 'num_train_epochs': 9, 'layer_decay': 0.9385501488469521}. Best is trial 11 with value: 0.8868905874305938.\n",
            "======= Tuning finished: stage3_broad | best f1_weighted=0.8869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1330159245.py:150: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5145' max='12348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 5145/12348 04:25 < 06:11, 19.39 it/s, Epoch 5/12]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.656700</td>\n",
              "      <td>0.608345</td>\n",
              "      <td>0.740525</td>\n",
              "      <td>0.740525</td>\n",
              "      <td>0.749467</td>\n",
              "      <td>0.737750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.434100</td>\n",
              "      <td>0.402128</td>\n",
              "      <td>0.844145</td>\n",
              "      <td>0.844145</td>\n",
              "      <td>0.848885</td>\n",
              "      <td>0.844039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.322500</td>\n",
              "      <td>0.379350</td>\n",
              "      <td>0.866254</td>\n",
              "      <td>0.866254</td>\n",
              "      <td>0.869690</td>\n",
              "      <td>0.866641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.193600</td>\n",
              "      <td>0.390666</td>\n",
              "      <td>0.853741</td>\n",
              "      <td>0.853741</td>\n",
              "      <td>0.856611</td>\n",
              "      <td>0.853582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.164600</td>\n",
              "      <td>0.498355</td>\n",
              "      <td>0.860058</td>\n",
              "      <td>0.860058</td>\n",
              "      <td>0.864477</td>\n",
              "      <td>0.859938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='189' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= Final best weights saved to: /content/drive/MyDrive/deep_learning/HF_best_model_stage3b.pt\n",
            "Stage 3b — Validation: {'eval_loss': 0.4983547329902649, 'eval_accuracy': 0.8600583090379009, 'eval_f1_micro': 0.8600583090379009, 'eval_f1_macro': 0.864477472517444, 'eval_f1_weighted': 0.8599380727527254, 'eval_runtime': 2.3104, 'eval_samples_per_second': 3563.037, 'eval_steps_per_second': 55.835, 'epoch': 5.0}\n",
            "Stage 3b — Test: {'eval_loss': 0.5515292286872864, 'eval_accuracy': 0.8430753027909426, 'eval_f1_micro': 0.8430753027909426, 'eval_f1_macro': 0.8474695537131105, 'eval_f1_weighted': 0.8429512336449717, 'eval_runtime': 1.2776, 'eval_samples_per_second': 2972.719, 'eval_steps_per_second': 46.962, 'epoch': 5.0}\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# 12) Fresh run (Stage 3b): tune → final → save weights to Drive\n",
        "#     - Change N_TRIALS if you want more/less\n",
        "# ========================================\n",
        "N_TRIALS = 12\n",
        "best_params_s3b, best_val_s3b = tune_once(\n",
        "    config_name=\"stage3_broad\",\n",
        "    search_space_fn=search_space_stage3b,\n",
        "    n_trials=N_TRIALS,\n",
        "    tune_epochs=(4,6)\n",
        ")\n",
        "\n",
        "save_path_s3b, val_metrics_s3, test_metrics_s3b = final_train_and_save(\n",
        "    config_name=\"stage3b_broad\",\n",
        "    best_params=best_params_s3b,\n",
        "    final_epochs=12,\n",
        "    save_name=\"HF_best_model_stage3b.pt\"\n",
        ")\n",
        "\n",
        "print(\"Stage 3b — Validation:\", val_metrics_s3)\n",
        "print(\"Stage 3b — Test:\", test_metrics_s3b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kCYulHXd3-H"
      },
      "source": [
        "**Stage 3b underperformed relative to earlier stages**, so we stopped the search. With DLR + non-zero warmup in Stage 3 we reached val F1-macro 0.8877 and test F1-macro 0.8644, improving on Stage 2 (0.8763 / 0.8589). In contrast, Stage 3b—run with a tighter LR band, higher warmup, moderate dropout/weight-decay, and only ~5 epochs—regressed to val 0.8645 and test 0.8475. The likely causes are:\n",
        "\n",
        "\n",
        "1.  over-regularization (dropout + WD + label smoothing)\n",
        "2.  too much warmup for a short training budget (fewer effective post-warmup updates)\n",
        "3. a layer-decay that slowed lower layers more than needed under this budget.\n",
        "\n",
        "Given diminishing returns and limited time, we stopped after Stage 3b and selected the Stage 3 configuration as the final model. (If we had the time , we would re-train the Stage 3 best with 2–3 seeds for robustness and optionally retune layer_decay/warmup with a longer schedule.)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06eac6d31845463caa2dd1d2e0cf04ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095b25d04604468e9c8598782e565265": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aeb654603686466caadbd0fd836f9188",
              "IPY_MODEL_7e4bb7c45016421c99ee67ae9d7afac6",
              "IPY_MODEL_9980398d43f7440daa1258cd28fc5e99"
            ],
            "layout": "IPY_MODEL_06eac6d31845463caa2dd1d2e0cf04ff"
          }
        },
        "0cbe3879ff58474aa9460ae8ee19894c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab7cab50472d45489e4eb550756b20ff",
            "placeholder": "​",
            "style": "IPY_MODEL_294d397714ac4e77958f445f768f78f2",
            "value": " 12/12 [1:01:21&lt;00:00, 353.61s/it]"
          }
        },
        "110968ccca1a4631b83d51f0ac704f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d734f5190d8b49fcab100dc5304ce6aa",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_901a99469a8242cebe6c413f71800900",
            "value": 440449768
          }
        },
        "194cdc198a9a47378651b68c85efbf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a2216f93d1a454b99695b3f0a79687a",
              "IPY_MODEL_3cb9ba69052d485dab0e4726daea215d",
              "IPY_MODEL_0cbe3879ff58474aa9460ae8ee19894c"
            ],
            "layout": "IPY_MODEL_6ad7c9ac909b44e1903182ab0c072860"
          }
        },
        "1f23fb78613f45cb971296f08d6c7aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "267fe7251fb449078a9127f6b876c29f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "294d397714ac4e77958f445f768f78f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cb9ba69052d485dab0e4726daea215d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb7793a3904046ccab6e30631c4fe936",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2a80fa80c934968837832494a5b00a8",
            "value": 12
          }
        },
        "40d8878761f541d58a0131301ce072ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_640aa3c6ed764d46b960b762e5dd567a",
              "IPY_MODEL_110968ccca1a4631b83d51f0ac704f5b",
              "IPY_MODEL_e1b90a08d0f64e52ad4c4fb66dd4fce3"
            ],
            "layout": "IPY_MODEL_ab7fa6ed372d426a84366d4517f12841"
          }
        },
        "5a2216f93d1a454b99695b3f0a79687a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b3be77f0084c88b14ed4664e8a6b8f",
            "placeholder": "​",
            "style": "IPY_MODEL_b8b857824ff945fa89d7a80e241384db",
            "value": "Best trial: 11. Best value: 0.881375: 100%"
          }
        },
        "5da63b03166e4686a5335785dd7bf6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640aa3c6ed764d46b960b762e5dd567a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f00b51f51749b598e87019886b302f",
            "placeholder": "​",
            "style": "IPY_MODEL_d6fe8f9709614a6cbc3b1ff51ba055a1",
            "value": "model.safetensors: 100%"
          }
        },
        "6ad7c9ac909b44e1903182ab0c072860": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77feed77f5514088a7283ef8d00d6dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e4bb7c45016421c99ee67ae9d7afac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5da63b03166e4686a5335785dd7bf6d8",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93d0fcf524e24255a74038298c8060e7",
            "value": 2
          }
        },
        "901a99469a8242cebe6c413f71800900": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90d46e9171b248c599c5827767518468": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93d0fcf524e24255a74038298c8060e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9980398d43f7440daa1258cd28fc5e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d46e9171b248c599c5827767518468",
            "placeholder": "​",
            "style": "IPY_MODEL_77feed77f5514088a7283ef8d00d6dbd",
            "value": " 2/12 [13:58&lt;1:12:46, 436.64s/it]"
          }
        },
        "a2a80fa80c934968837832494a5b00a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa45d1716fc446ffa3015a00b3ed7283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7cab50472d45489e4eb550756b20ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab7fa6ed372d426a84366d4517f12841": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb654603686466caadbd0fd836f9188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd0d1229c117478498d20eaa7912253d",
            "placeholder": "​",
            "style": "IPY_MODEL_aa45d1716fc446ffa3015a00b3ed7283",
            "value": "Best trial: 0. Best value: 0.85006:  17%"
          }
        },
        "b8b857824ff945fa89d7a80e241384db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb7793a3904046ccab6e30631c4fe936": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0b3be77f0084c88b14ed4664e8a6b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6fe8f9709614a6cbc3b1ff51ba055a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d734f5190d8b49fcab100dc5304ce6aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f00b51f51749b598e87019886b302f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b90a08d0f64e52ad4c4fb66dd4fce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_267fe7251fb449078a9127f6b876c29f",
            "placeholder": "​",
            "style": "IPY_MODEL_1f23fb78613f45cb971296f08d6c7aa2",
            "value": " 440M/440M [00:01&lt;00:00, 447MB/s]"
          }
        },
        "fd0d1229c117478498d20eaa7912253d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0b96efa8f54416da55b0422eae67615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28150c8c3ef34365b6adf1415b8f79ca",
              "IPY_MODEL_bb00e98ee4db4b88b14ebcd7f2341196",
              "IPY_MODEL_7885e6cf852c4ef1b06700d3c24a330c"
            ],
            "layout": "IPY_MODEL_a13e5cf894b04658a2194817e589b8e9"
          }
        },
        "28150c8c3ef34365b6adf1415b8f79ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803192f0d8ef4614a8a06484581ce909",
            "placeholder": "​",
            "style": "IPY_MODEL_1fba0344ea2d42f0bb5a6e4bc23ddb37",
            "value": "Map: 100%"
          }
        },
        "bb00e98ee4db4b88b14ebcd7f2341196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac3b2905e32d4eddac6f91ed42d63ae5",
            "max": 32925,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01b7fd33a6bc498bb9eb8f729ed098e2",
            "value": 32925
          }
        },
        "7885e6cf852c4ef1b06700d3c24a330c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_712fdfcbfbe74a8e8ecbc77d865fc14f",
            "placeholder": "​",
            "style": "IPY_MODEL_515a21b75e40472eaad681eef51a103d",
            "value": " 32925/32925 [00:03&lt;00:00, 8518.98 examples/s]"
          }
        },
        "a13e5cf894b04658a2194817e589b8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803192f0d8ef4614a8a06484581ce909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fba0344ea2d42f0bb5a6e4bc23ddb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac3b2905e32d4eddac6f91ed42d63ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01b7fd33a6bc498bb9eb8f729ed098e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "712fdfcbfbe74a8e8ecbc77d865fc14f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "515a21b75e40472eaad681eef51a103d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79550c51f8a44fdcabb8b80b5e2eadb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5da9e33181a54abcabfebabc171a0574",
              "IPY_MODEL_2c5a5ca6f07743469342bc9a836232ff",
              "IPY_MODEL_b19b1c8f204742119cc18fb1f3bae855"
            ],
            "layout": "IPY_MODEL_46dd89328fee4a87b1c81dd36e1e1ec5"
          }
        },
        "5da9e33181a54abcabfebabc171a0574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e5903bb8c2a4c4bb84ce6bd7f2685ce",
            "placeholder": "​",
            "style": "IPY_MODEL_36785dee092f4722bb5e2878a661296b",
            "value": "Map: 100%"
          }
        },
        "2c5a5ca6f07743469342bc9a836232ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07cc04f190384e2fa50c6534081cbd79",
            "max": 8232,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eac1c486c0724ccfa4b393581f189f82",
            "value": 8232
          }
        },
        "b19b1c8f204742119cc18fb1f3bae855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d60813bfef2f4b058837cdcc0889526f",
            "placeholder": "​",
            "style": "IPY_MODEL_a48638c27e874e028eadfaac7f960dd9",
            "value": " 8232/8232 [00:01&lt;00:00, 7183.99 examples/s]"
          }
        },
        "46dd89328fee4a87b1c81dd36e1e1ec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e5903bb8c2a4c4bb84ce6bd7f2685ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36785dee092f4722bb5e2878a661296b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07cc04f190384e2fa50c6534081cbd79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eac1c486c0724ccfa4b393581f189f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d60813bfef2f4b058837cdcc0889526f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48638c27e874e028eadfaac7f960dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b02542bc0b548fba3c51ccea4e46f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63c857e4044748e998fafcbdb7179b6b",
              "IPY_MODEL_c93faa21bfcc4a6fae9c64eeed5101b4",
              "IPY_MODEL_920856563d5a441598fb7b9a538da4a5"
            ],
            "layout": "IPY_MODEL_be02dce09c054d39827fc1681431a990"
          }
        },
        "63c857e4044748e998fafcbdb7179b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a173d560e78405288fe55d6654354b3",
            "placeholder": "​",
            "style": "IPY_MODEL_bf7a14c5b4c44880b45c5b70a03d1898",
            "value": "Map: 100%"
          }
        },
        "c93faa21bfcc4a6fae9c64eeed5101b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4c5435005bc46f2bca3763ca14fee9d",
            "max": 3798,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d27accfe0d2143f2bd7dae848d05328d",
            "value": 3798
          }
        },
        "920856563d5a441598fb7b9a538da4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f90aee836994a2d87dbb3269b8eb49d",
            "placeholder": "​",
            "style": "IPY_MODEL_881ec87c6a5c47cb879e52aa7e03c341",
            "value": " 3798/3798 [00:00&lt;00:00, 8629.13 examples/s]"
          }
        },
        "be02dce09c054d39827fc1681431a990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a173d560e78405288fe55d6654354b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7a14c5b4c44880b45c5b70a03d1898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4c5435005bc46f2bca3763ca14fee9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d27accfe0d2143f2bd7dae848d05328d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f90aee836994a2d87dbb3269b8eb49d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "881ec87c6a5c47cb879e52aa7e03c341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}